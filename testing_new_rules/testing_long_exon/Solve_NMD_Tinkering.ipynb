{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gzip\n",
    "import argparse\n",
    "import pickle\n",
    "from statistics import mean, median\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "import pyfastx\n",
    "\n",
    "\n",
    "\n",
    "chrom = 'chr1'\n",
    "strand = '+'\n",
    "junc = [(1490671, 1495485), (1478745, 1479049), (1489274, 1489692), (1477350, 1478644), (1486235, 1486544), (1486668, 1489204), (1485838, 1486110), (1482614, 1485016), (1479108, 1480867), (1455519, 1523839), (1486668, 1487863), (1478351, 1478644), (1462708, 1477274), (1480908, 1482266), (1477350, 1477751), (1485171, 1485782), (1487914, 1489204), (1472089, 1477274), (1490424, 1490563), (1489274, 1490257), (1489811, 1490257), (1482303, 1482545), (1477350, 1480867), (1472306, 1477274), (1480936, 1482138)]\n",
    "start_codons = {(1471885, 1471887)}\n",
    "stop_codons = {(1495815, 1495817)}\n",
    "gene_name = 'ATAD3B'\n",
    "exonLcutoff=1000\n",
    "verbose=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 1, Seed L = 1\n",
      "Depth 2, Seed L = 1\n",
      "Depth 3, Seed L = 4\n",
      "Depth 4, Seed L = 3\n",
      "Depth 5, Seed L = 5\n",
      "Depth 6, Seed L = 4\n",
      "Depth 7, Seed L = 3\n",
      "Depth 8, Seed L = 4\n",
      "Depth 9, Seed L = 2\n",
      "Depth 10, Seed L = 1\n",
      "Depth 11, Seed L = 3\n",
      "Depth 12, Seed L = 2\n",
      "Depth 13, Seed L = 4\n",
      "Depth 14, Seed L = 6\n",
      "CRGSSALTRAPRVKARGRRRLCRPRSPGPRAAGTAVWETGRRPRTNGATSTPPAWSAPPRRRASWSTRVSAAGRGGAGGRAGRAGEAGALALAAPRCCRQPLPGRDCAPGAPPAGAVSRAGRIGLFPSPVCTSAAVRSGSGYAKEALNLAQMQEQTLQLEQQSKLKQLLNEENLRKQEESVQKQEAMRRATVEREMELRHKNEMLRVETEARARAKAERENADIIREQIRLKASEHRQTVLESIRTAGTLFGEGFRAFVTDRDKVTATVAGLTLLAVGVYSAKNATAVTGRFIEARLGKPSLVRETSRITVLEALRHPIQVSRRLLSRPQDVLEGVVLSPSLEARVRDIAIATRNTKKNRGLYRHILLYGPPGTGKTLFAKKLALHSGMDYAIMTGGDVAPMGREGVTAMHKLFDWANTSRRGLLLFMDEADAFLRKRATEEISKDLRATLNAFLYHMGQHSNKFMLVLASNLPEQFDCAINSRIDVMVHFDLPQQEERERLVRLHFDNCVLKPATEGKRRLKLAQFDYGRKCSEVARLTEGMSGREIAQLAVSWQATAYASKDGVLTEAMMDACVQDAVQQYRQKMRWLKAEGPGRGVEHPLSGVQGETLTSWSLATDPSYPCLAGPCTFRICSWMGTGLCPGPLSPRMSCGGGRPFCPPGHPLL*\n",
      "MSWLFGVNKGPKGEGAGPPPPLPPAQPGAEGGGDRGLGDRPAPKDKWSNFDPTGLERAAKAARELEHSRYAKEALNLAQMQEQTLQLEQQSKLKQLLNEENLRKQEESVQKQEAMRRATVEREMELRHKNEMLRVETEARARAKAERENADIIREQIRLKASEHRQTVLESIRTAGTLFGEGFRAFVTDRDKVTATVAGLTLLAVGVYSAKNATAVTGRFIEARLGKPSLVRETSRITVLEALRHPIQVSRRLLSRPQDVLEGVVLSPSLEARVRDIAIATRNTKKNRGLYRHILLYGPPGTGKTLFAKKLALHSGMDYAIMTGGDVAPMGREGVTAMHKLFDWANTSRRGLLLFMDEADAFLRKRATEEISKDLRATLNAFLYHMGQHSNKFMLVLASNLPEQFDCAINSRIDVMVHFDLPQQEERERLVRLHFDNCVLKPATEGKRRLKLAQFDYGRKCSEVARLTEGMSGREIAQLAVSWQATAYASKDGVLTEAMMDACVQDAVQQYRQKMRWLKAEGPGRGVEHPLSGVQGETLTSWSLATDPSYPCLAGPCTFRICSWMGTGLCPGPLSPRMSCGGGRPFCPPGHPLL*\n",
      "Depth 15, Seed L = 3\n",
      "Depth 16, Seed L = 4\n",
      "junction pass(1480908, 1482266)junction pass(1479108, 1480867)junction pass(1478745, 1479049)junction pass(1477350, 1478644)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Compute whether there is a possible combination that uses the junction without\n",
    "inducing a PTC. We start with all annotated stop codon and go backwards.\n",
    "'''\n",
    "\n",
    "fa = pyfastx.Fasta('genome.fa')\n",
    "\n",
    "seed = []\n",
    "\n",
    "junc.sort()\n",
    "if strand == \"+\":\n",
    "    junc.reverse()\n",
    "    \n",
    "\"\"\"Quinn Comment: Adds all 'stop codons' to a nested list called seed\"\"\" \n",
    "##in an individual transcript    \n",
    "for c in stop_codons:\n",
    "    if strand == \"+\":\n",
    "        seed.append([c[1]])\n",
    "    else:\n",
    "        seed.append([c[0]])\n",
    "\n",
    "# seed starts with just stop codon and then a possible 3'ss-5'ss junction\n",
    "# without introducing a PTC [stop_codon,3'ss, 5'ss, 3'ss, ..., start_codon]\n",
    "\n",
    "junc_pass = {}\n",
    "junc_fail = {}\n",
    "path_pass = []\n",
    "proteins = []\n",
    "\n",
    "dic_terminus = {}\n",
    "\n",
    "depth = 0\n",
    "\n",
    "\n",
    "#seed = [[25832088, 25832158, 25835022, 25835846, 25837413], [25832088, 25832158, 25835022, 25835846, 25859280]]\n",
    "\n",
    "\n",
    "\"\"\"Quinn Comment: while our seed length is greater than 0 - which means we have charted all possible paths through \n",
    "all junctions ending in a stop codon (or there is an exon longer than 1000 bp and we have no complete paths)\"\"\"\n",
    "while len(seed) > 0:\n",
    "\n",
    "    new_seed = []\n",
    "    final_check = []\n",
    "    depth += 1\n",
    "    if verbose:\n",
    "        sys.stdout.write(\"Depth %s, Seed L = %s\\n\"%(depth, len(seed)))\n",
    "    #print(start_codons, [s[-1] for s in seed][-10:], len(junc))\n",
    "    framepos = {}\n",
    "            \n",
    "    for s in seed:\n",
    "        # first check that the seed paths are good        \n",
    "        bool_ptc = False\n",
    "        leftover = ''\n",
    "        if len(s) > 0:            \n",
    "            leftover = Seq(\"\")\n",
    "            allprot = Seq(\"\")\n",
    "\n",
    "            \"\"\"Quinn Comment: loop through the exons, calculating lengths\"\"\"\n",
    "            for i in range(0, len(s)-1, 2):\n",
    "                exon_coord = s[i:i+2]\n",
    "                exon_coord.sort()\n",
    "                exon_coord = tuple(exon_coord)\n",
    "                exlen = exon_coord[1]-exon_coord[0]\n",
    "\n",
    "\n",
    "                \"\"\"Quinn Comment: find start position relative to named start of this exon and translate to protein\"\"\"\n",
    "                startpos = (len(leftover)+exlen+1)%3\n",
    "                if strand == '+':\n",
    "                    seq = Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))+leftover \n",
    "                    prot = seq[startpos:].translate()\n",
    "                    leftover = seq[:startpos]                                                                                                               \n",
    "                    allprot = prot+allprot  \n",
    "                else:\n",
    "                    seq = leftover+Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))\n",
    "                    aseq = seq\n",
    "                    if startpos > 0:\n",
    "                        leftover = seq[-startpos:]\n",
    "                    else:\n",
    "                        leftover = Seq(\"\")\n",
    "                    seq = seq.reverse_complement()\n",
    "                    prot = seq[startpos:].translate()\n",
    "                    allprot = prot+allprot\n",
    "\n",
    "                #found a PTC in this transcript if any element but the last is a stop codon   \n",
    "                bool_ptc = \"*\" in allprot[:-1]\n",
    "        \"\"\"Quinn Comment: if we found a PTC, add all intron coordinate pairs involved in the transcript to junc_fail\"\"\" \n",
    "               \n",
    "        if bool_ptc:\n",
    "            #This transcript failed\n",
    "            for i in range(1, len(s)-1, 2):                                                                                                                  \n",
    "                j_coord = s[i:i+2]                                                                                                                           \n",
    "                j_coord.sort()                                                                                                                             \n",
    "                j_coord = tuple(j_coord)                                                                                                                     \n",
    "                if j_coord not in junc_fail:                                                                                                                 \n",
    "                    junc_fail[j_coord] = 0                                                                                                                   \n",
    "                junc_fail[j_coord] += 1  \n",
    "            continue\n",
    "    \n",
    "        # passed\n",
    "        \"\"\"Quinn Comment: if we don't just have a stop codon, create a terminus for this \n",
    "        seed at the last 3' splice site or start codon; terminus is last two coordinates and the reading frame, \n",
    "        used for dynamic programming later\"\"\"\n",
    "        if len(s) > 2:\n",
    "            terminus = (s[-2],s[-1],leftover)\n",
    "            \n",
    "\n",
    "            ###THIS LINE IS KEY FOR DYNAMIC PROGRAMMING BEHAVIOR\n",
    "            if terminus in dic_terminus:\n",
    "                dic_terminus[terminus].append(tuple(s))\n",
    "                continue\n",
    "            else:\n",
    "                dic_terminus[terminus] = [tuple(s)]\n",
    "        \n",
    "        last_pos = s[-1]\n",
    "        \"\"\"Quinn Comment: check the last position of our seed to see if it is close to a start codon, within a potential exon's length,\n",
    "            and add your seed plus this start codon to final_check \"\"\"\n",
    "        for start in start_codons:                \n",
    "            #print(\"start\", start, abs(last_pos-start[0]))\n",
    "            if strand == \"+\" and last_pos > start[0] and abs(last_pos-start[0]) < exonLcutoff:\n",
    "                final_check.append(s+[start[0]])\n",
    "            elif strand == \"-\" and last_pos < start[1] and abs(last_pos-start[1]) < exonLcutoff:\n",
    "                final_check.append(s+[start[1]]) \n",
    "\n",
    "        \"\"\"Quinn Comment: add all possible places to go from our last_pos to the seed (nested list)\"\"\"\n",
    "        for j0,j1 in junc:                \n",
    "            if strand == \"+\" and last_pos > j1 and abs(last_pos-j1) < exonLcutoff:\n",
    "                new_seed.append(s+[j1,j0])\n",
    "            #print(\"junction\", (j0,j1), abs(last_pos-j0))\n",
    "            if strand == \"-\" and last_pos < j0 and abs(last_pos-j0) < exonLcutoff: \n",
    "                new_seed.append(s+[j0,j1])\n",
    "                \n",
    "    \"\"\"Quinn Comment: Exited from s in seed loop, now we check our final_checks of the full paths, we do not\n",
    "    eliminate paths based on presence of a PTC, rather we classify full complete paths without PTCs if they exist\"\"\"\n",
    "    # check that the possible final paths are good\n",
    "    for s in final_check:\n",
    "\n",
    "        leftover = Seq(\"\")\n",
    "        allprot = Seq(\"\")\n",
    "        for i in range(0, len(s)-1, 2):\n",
    "            exon_coord = s[i:i+2]\n",
    "            exon_coord.sort()\n",
    "            exon_coord = tuple(exon_coord)\n",
    "            exlen = exon_coord[1]-exon_coord[0]\n",
    "            startpos = (len(leftover)+exlen+1)%3\n",
    "            if strand == \"+\":\n",
    "                seq = Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))+leftover\n",
    "                leftover = seq[:startpos]  \n",
    "                prot = seq[startpos:].translate()\n",
    "                allprot = prot+allprot\n",
    "            else:\n",
    "                seq = leftover+Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))\n",
    "                if startpos > 0:                                                                                                    \n",
    "                    leftover = seq[-startpos:]                                    \n",
    "                else:\n",
    "                    leftover = Seq(\"\")\n",
    "                seq = seq.reverse_complement()                                                                                                           \n",
    "                prot = seq[startpos:].translate()                                                                                                        \n",
    "                allprot = prot+allprot                      \n",
    "        bool_ptc = \"*\" in allprot[:-1]\n",
    "        \"\"\"Quinn Comment: Classify seed + start codon as a passing path if no PTCs found in previous block of code\"\"\"\n",
    "        if not bool_ptc:\n",
    "            print(allprot)\n",
    "            # all pass\n",
    "            proteins.append(\"\\t\".join([gene_name,chrom,strand, \"-\".join([str(x) for x in s]), str(allprot)])+'\\n')\n",
    "            #print(\"ALL PASS %s\"%(s))\n",
    "            path_pass.append(tuple(s))\n",
    "            for i in range(1, len(s), 2):\n",
    "                j_coord = s[i:i+2]\n",
    "                j_coord.sort()\n",
    "                j_coord = tuple(j_coord)\n",
    "                if j_coord not in junc_pass:\n",
    "                    junc_pass[j_coord] = 0\n",
    "                junc_pass[j_coord] += 1\n",
    "\n",
    "    seed = new_seed\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Quinn Comment: OUT OF WHILE LOOP through all possible paths/seeds; \n",
    "check all junctions that end in termini that eventually pass \n",
    "to see if they are part of a full path that has been classified as passing\"\"\"\n",
    "while True:\n",
    "    new_paths = []\n",
    "    for terminus in dic_terminus:\n",
    "        terminus_pass = False\n",
    "        for path_subset in dic_terminus[terminus]:\n",
    "            for path in path_pass:\n",
    "                if path[:len(path_subset)] == path_subset:\n",
    "                    terminus_pass = True\n",
    "                    break\n",
    "        #print(terminus, terminus_pass)\n",
    "\n",
    "        \"\"\"Quinn Comment: add all junctions from a passing terminus to junc_pass\"\"\"\n",
    "        if terminus_pass:\n",
    "            for path_subset in dic_terminus[terminus]:\n",
    "                if path_subset in path_pass: continue\n",
    "                new_paths.append(path_subset)\n",
    "                path_pass.append(path_subset)\n",
    "                for i in range(1, len(path_subset), 2):\n",
    "                    j_coord = list(path_subset[i:i+2])\n",
    "                    j_coord.sort()\n",
    "                    j_coord = tuple(j_coord)\n",
    "                    if j_coord not in junc_pass:\n",
    "                        junc_pass[j_coord] = 0\n",
    "                        if verbose:\n",
    "                            sys.stdout.write(\"junction pass\" + str(j_coord))\n",
    "    \"\"\"Quinn Comment: we could have a new path_pass added, so our while loop checks again to see if there are any new paths \n",
    "    that are now going to be passing considering our additions\"\"\"\n",
    "    if len(new_paths) == 0:\n",
    "        break\n",
    "        \n",
    "#junc_pass,junc_fail,proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1490671, 1495485): 2,\n",
       " (1490424, 1490563): 2,\n",
       " (1489274, 1490257): 2,\n",
       " (1487914, 1489204): 2,\n",
       " (1486668, 1487863): 2,\n",
       " (1486235, 1486544): 2,\n",
       " (1485838, 1486110): 2,\n",
       " (1485171, 1485782): 2,\n",
       " (1482614, 1485016): 2,\n",
       " (1482303, 1482545): 2,\n",
       " (1480936, 1482138): 2,\n",
       " (1477350, 1480867): 2,\n",
       " (1472306, 1477274): 1,\n",
       " (1471885,): 2,\n",
       " (1472089, 1477274): 1,\n",
       " (1480908, 1482266): 0,\n",
       " (1479108, 1480867): 0,\n",
       " (1478745, 1479049): 0,\n",
       " (1477350, 1478644): 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junc_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 1, Seed L = 1\n",
      "Depth 2, Seed L = 1\n",
      "Depth 3, Seed L = 4\n",
      "Depth 4, Seed L = 10\n",
      "Depth 5, Seed L = 9\n",
      "Depth 6, Seed L = 10\n",
      "Depth 7, Seed L = 12\n",
      "Depth 8, Seed L = 13\n",
      "Depth 9, Seed L = 17\n",
      "long_exon:\n",
      "CRGSSALTRAPRVKARGRRRLCRPRSPGPRAAGTAVWETGRRPRTNGATSTPPAWSAPPRRRASWSTRVSAAGRGGAGGRAGRAGEAGALALAAPRCCRQPLPGRDCAPGAPPAGAVSRAGRIGLFPSPVCTSAAVRSGSGYAKEALNLAQMQEQTLQLEQQSKLKQLLNEENLRKQEESVQKQEAMRRATVEREMELRHKNEMLRVETEARARAKAERENADIIREQIRLKASEHRQTVLESIR@ALPRPGPATDGAPQV@VAGPRALSSSSRPGRHRLTPWWGHCPSVLARPCRHVRASPSTCSRCVVRIFVSFLVTPLLSPQDGWHLVWGRIPCLCDRPGQSDSHGGWADAAGCRGLLSQECDSRHWPLHRGSAGEAVPSEGDVPHHGAGGAAAPHPGSGAGLALPECSSWLSPFCPTSTAHAHPPVPSLSPDNRHPHAASRVGFPVWRCTLGVCISETLPLSASVSLAQGS@WGLGAHRGPCKTRDLGVRPSVGEAATGHGVWWPPWGAAPLASP@GACSPQVTG@VVKKIKANKEPENAPNPSNSLLVSRRGRVPAPGRSWLCFGAAPFLCVTEHVCALVAVPWLWQVTQWCFPFPSGRSAGGSSVDPRTCWRVLCLVPAWKHGCATSP@QPGTPRRTGACTGTSCCMGHQAPGRRCLPR@ERLAEQVGQGPLGSHLPAGVWGPQPPGEWTPLRPLPTLV@AQGAGVGSSASHLPGGGRLLSGRLWLPDRDTRQGLHTPGGVCRLCRGRGNICSVSPHSSCPETRPALRHGLRHHDRRGRGPHGAGRRDRHAQAL@LGQYQPAREEISKDLRATLNAFLYHMGQHSNK@GSPSGPEPPGRAVQPSPLVPTEGPWLTVLGTSCGLSVPTSDVPWERPSSGQHGVSLRNMQGPPGQSWGQSCLHGPVRRRPSLQVPLPLDFCGPVPAREVV@LLPPRGPQ@GDRPYVQAPSSLPNPLILSFLGLLGPSSPSHVSHGGSSPAGRPWLTLQARWAPGSAAAVRRSLEP@LRFMLVLASNLPEQFDCAINSRIDVMVHFDLPQQEERERLVRLHFDNCVLKPATEGKR@VSRLTRPPIQAPYGMGVGQLPVFRPPPHGVGSAALAASLGNSFPRRLKLAQFDYGRKCSEVARLTEGMSGREIAQLAVSWQATAYASKDGVLTEAMMDACVQDAVQQYRQKMRWLKAEGPGRGVEHPLSGVQGETLTSWSLATDPSYPCLAGPCTFRICSWMGTGLCPGPLSPRMSCGGGRPFCPPGHPLL*\n",
      "long_exon:\n",
      "MSWLFGVNKGPKGEGAGPPPPLPPAQPGAEGGGDRGLGDRPAPKDKWSNFDPTGLERAAKAARELEHSRYAKEALNLAQMQEQTLQLEQQSKLKQLLNEENLRKQEESVQKQEAMRRATVEREMELRHKNEMLRVETEARARAKAERENADIIREQIRLKASEHRQTVLESIR@ALPRPGPATDGAPQV@VAGPRALSSSSRPGRHRLTPWWGHCPSVLARPCRHVRASPSTCSRCVVRIFVSFLVTPLLSPQDGWHLVWGRIPCLCDRPGQSDSHGGWADAAGCRGLLSQECDSRHWPLHRGSAGEAVPSEGDVPHHGAGGAAAPHPGSGAGLALPECSSWLSPFCPTSTAHAHPPVPSLSPDNRHPHAASRVGFPVWRCTLGVCISETLPLSASVSLAQGS@WGLGAHRGPCKTRDLGVRPSVGEAATGHGVWWPPWGAAPLASP@GACSPQVTG@VVKKIKANKEPENAPNPSNSLLVSRRGRVPAPGRSWLCFGAAPFLCVTEHVCALVAVPWLWQVTQWCFPFPSGRSAGGSSVDPRTCWRVLCLVPAWKHGCATSP@QPGTPRRTGACTGTSCCMGHQAPGRRCLPR@ERLAEQVGQGPLGSHLPAGVWGPQPPGEWTPLRPLPTLV@AQGAGVGSSASHLPGGGRLLSGRLWLPDRDTRQGLHTPGGVCRLCRGRGNICSVSPHSSCPETRPALRHGLRHHDRRGRGPHGAGRRDRHAQAL@LGQYQPAREEISKDLRATLNAFLYHMGQHSNK@GSPSGPEPPGRAVQPSPLVPTEGPWLTVLGTSCGLSVPTSDVPWERPSSGQHGVSLRNMQGPPGQSWGQSCLHGPVRRRPSLQVPLPLDFCGPVPAREVV@LLPPRGPQ@GDRPYVQAPSSLPNPLILSFLGLLGPSSPSHVSHGGSSPAGRPWLTLQARWAPGSAAAVRRSLEP@LRFMLVLASNLPEQFDCAINSRIDVMVHFDLPQQEERERLVRLHFDNCVLKPATEGKR@VSRLTRPPIQAPYGMGVGQLPVFRPPPHGVGSAALAASLGNSFPRRLKLAQFDYGRKCSEVARLTEGMSGREIAQLAVSWQATAYASKDGVLTEAMMDACVQDAVQQYRQKMRWLKAEGPGRGVEHPLSGVQGETLTSWSLATDPSYPCLAGPCTFRICSWMGTGLCPGPLSPRMSCGGGRPFCPPGHPLL*\n",
      "Depth 10, Seed L = 18\n",
      "Depth 11, Seed L = 13\n",
      "long_exon:\n",
      "MSWLFGVNKGPKGEGAGPPPPLPPAQPGAEGGGDRGLGDRPAPKDKWSNFDPTGLERAAKAARELEHSRECGGAGRGGRAGGTGRGSGSPGPCRSSLLSAATSRARLRPRSTPGRSRLACREDRTLSVTRLHLCSCQERVRLRQGGPESGADAGADAAVGATVQAQSWSAMAQSRLTATSASRVQAIHLPQPLE@LGLQARATTPG@CCILVETGFLHVGQAGL@LPTSGDPPASASQTAGITGTRHHAWPILFYFETECHSVPQSGVQWFDLGSLQPPPPGFNLLPQPSEQLGLQEPATTSGEFLYF@@RRGFSMLSRLVLNS@PQVIQPLWPHKVLGL@ARAMAPGPLSRIPRMGTSSALITVQK@APAWSCPETALWGGVGV@PPSPGAFAGFSAGASVPVGLDSSRA@SWVQMQLEALNLLHTLVWARSLCRAGAVQTQERLSGSASPEQVPAGECCALQEYEAAVEQLKSEQIRAQAEERRKTLSEETRQHQARAQYQDKLARQRYEDQLKQQQLLNEENLRKQEESVQKQEAMRRATVEREMELRHKNEMLRVETEARARAKAERENADIIREQIRLKASEHRQTVLESIR@ALPRPGPATDGAPQV@VAGPRALSSSSRPGRHRLTPWWGHCPSVLARPCRHVRASPSTCSRCVVRIFVSFLVTPLLSPQDGWHLVWGRIPCLCDRPGQSDSHGGWADAAGCRGLLSQECDSRHWPLHRGSAGEAVPSEGDVPHHGAGGAAAPHPGSGAGLALPECSSWLSPFCPTSTAHAHPPVPSLSPDNRHPHAASRVGFPVWRCTLGVCISETLPLSASVSLAQGS@WGLGAHRGPCKTRDLGVRPSVGEAATGHGVWWPPWGAAPLASP@GACSPQVTG@VVKKIKANKEPENAPNPSNSLLVSRRGRVPAPGRSWLCFGAAPFLCVTEHVCALVAVPWLWQVTQWCFPFPSGRSAGGSSVDPRTCWRVLCLVPAWKHGCATSP@QPGTPRRTGACTGTSCCMGHQAPGRRCLPR@ERLAEQVGQGPLGSHLPAGVWGPQPPGEWTPLRPLPTLV@AQGAGVGSSASHLPGGGRLLSGRLWLPDRDTRQGLHTPGGVCRLCRGRGNICSVSPHSSCPETRPALRHGLRHHDRRGRGPHGAGRRDRHAQAL@LGQYQPAREEISKDLRATLNAFLYHMGQHSNK@GSPSGPEPPGRAVQPSPLVPTEGPWLTVLGTSCGLSVPTSDVPWERPSSGQHGVSLRNMQGPPGQSWGQSCLHGPVRRRPSLQVPLPLDFCGPVPAREVV@LLPPRGPQ@GDRPYVQAPSSLPNPLILSFLGLLGPSSPSHVSHGGSSPAGRPWLTLQARWAPGSAAAVRRSLEP@LRFMLVLASNLPEQFDCAINSRIDVMVHFDLPQQEERERLVRLHFDNCVLKPATEGKR@VSRLTRPPIQAPYGMGVGQLPVFRPPPHGVGSAALAASLGNSFPRRLKLAQFDYGRKCSEVARLTEGMSGREIAQLAVSWQATAYASKDGVLTEAMMDACVQDAVQQYRQKMRWLKAEGPGRGVEHPLSGVQGETLTSWSLATDPSYPCLAGPCTFRICSWMGTGLCPGPLSPRMSCGGGRPFCPPGHPLL*\n",
      "Depth 12, Seed L = 2\n",
      "Depth 13, Seed L = 4\n",
      "Depth 14, Seed L = 6\n",
      "normal:\n",
      "CRGSSALTRAPRVKARGRRRLCRPRSPGPRAAGTAVWETGRRPRTNGATSTPPAWSAPPRRRASWSTRVSAAGRGGAGGRAGRAGEAGALALAAPRCCRQPLPGRDCAPGAPPAGAVSRAGRIGLFPSPVCTSAAVRSGSGYAKEALNLAQMQEQTLQLEQQSKLKQLLNEENLRKQEESVQKQEAMRRATVEREMELRHKNEMLRVETEARARAKAERENADIIREQIRLKASEHRQTVLESIRTAGTLFGEGFRAFVTDRDKVTATVAGLTLLAVGVYSAKNATAVTGRFIEARLGKPSLVRETSRITVLEALRHPIQVSRRLLSRPQDVLEGVVLSPSLEARVRDIAIATRNTKKNRGLYRHILLYGPPGTGKTLFAKKLALHSGMDYAIMTGGDVAPMGREGVTAMHKLFDWANTSRRGLLLFMDEADAFLRKRATEEISKDLRATLNAFLYHMGQHSNKFMLVLASNLPEQFDCAINSRIDVMVHFDLPQQEERERLVRLHFDNCVLKPATEGKRRLKLAQFDYGRKCSEVARLTEGMSGREIAQLAVSWQATAYASKDGVLTEAMMDACVQDAVQQYRQKMRWLKAEGPGRGVEHPLSGVQGETLTSWSLATDPSYPCLAGPCTFRICSWMGTGLCPGPLSPRMSCGGGRPFCPPGHPLL*\n",
      "normal:\n",
      "MSWLFGVNKGPKGEGAGPPPPLPPAQPGAEGGGDRGLGDRPAPKDKWSNFDPTGLERAAKAARELEHSRYAKEALNLAQMQEQTLQLEQQSKLKQLLNEENLRKQEESVQKQEAMRRATVEREMELRHKNEMLRVETEARARAKAERENADIIREQIRLKASEHRQTVLESIRTAGTLFGEGFRAFVTDRDKVTATVAGLTLLAVGVYSAKNATAVTGRFIEARLGKPSLVRETSRITVLEALRHPIQVSRRLLSRPQDVLEGVVLSPSLEARVRDIAIATRNTKKNRGLYRHILLYGPPGTGKTLFAKKLALHSGMDYAIMTGGDVAPMGREGVTAMHKLFDWANTSRRGLLLFMDEADAFLRKRATEEISKDLRATLNAFLYHMGQHSNKFMLVLASNLPEQFDCAINSRIDVMVHFDLPQQEERERLVRLHFDNCVLKPATEGKRRLKLAQFDYGRKCSEVARLTEGMSGREIAQLAVSWQATAYASKDGVLTEAMMDACVQDAVQQYRQKMRWLKAEGPGRGVEHPLSGVQGETLTSWSLATDPSYPCLAGPCTFRICSWMGTGLCPGPLSPRMSCGGGRPFCPPGHPLL*\n",
      "Depth 15, Seed L = 3\n",
      "Depth 16, Seed L = 4\n",
      "junction long_exon:(1489274, 1490257)junction long_exon:(1490424, 1490563)junction long_exon:(1485171, 1485782)junction long_exon:(1487914, 1489204)junction long_exon:(1486668, 1487863)junction long_exon:(1482303, 1482545)junction long_exon:(1480908, 1482266)junction long_exon:(1477350, 1478644)junction long_exon:(1478351, 1478644)junction long_exon:(1486235, 1486544)"
     ]
    }
   ],
   "source": [
    "junc.sort()\n",
    "if strand == \"+\":\n",
    "    junc.reverse()\n",
    "    \n",
    "\"\"\"Quinn Comment: Adds all 'stop codons' to a nested list called seed\"\"\" \n",
    "##in an individual transcript    \n",
    "for c in stop_codons:\n",
    "    if strand == \"+\":\n",
    "        seed.append([c[1]])\n",
    "    else:\n",
    "        seed.append([c[0]])\n",
    "\n",
    "# seed starts with just stop codon and then a possible 3'ss-5'ss junction\n",
    "# without introducing a PTC [stop_codon,3'ss, 5'ss, 3'ss, ..., start_codon]\n",
    "\n",
    "junc_pass = {'long_exon':{}, 'long_exon':{}}\n",
    "junc_fail = {}\n",
    "path_pass = {'long_exon':[], 'long_exon':[]}\n",
    "proteins = []\n",
    "\n",
    "dic_terminus = {'normal': {}, 'long_exon': {}}\n",
    "\n",
    "depth = 0\n",
    "\n",
    "\"\"\"Quinn Comment: while our seed length is greater than 0 - which means we have charted all possible paths through \n",
    "all junctions ending in a stop codon (or there is an exon longer than 1000 bp and we have no complete paths)\"\"\"\n",
    "while len(seed) > 0:\n",
    "    new_seed = []\n",
    "    final_check = []\n",
    "    depth += 1\n",
    "    if verbose:\n",
    "        sys.stdout.write(\"Depth %s, Seed L = %s\\n\"%(depth, len(seed)))\n",
    "    #print(start_codons, [s[-1] for s in seed][-10:], len(junc))\n",
    "    framepos = {}\n",
    "                \n",
    "    for s in seed:\n",
    "        # first check that the seed paths are good        \n",
    "        bool_ptc = False\n",
    "        leftover = ''\n",
    "        if len(s) > 0:                \n",
    "            leftover = Seq(\"\")\n",
    "            allprot = Seq(\"\")\n",
    "\n",
    "            \"\"\"Quinn Comment: loop through the exons, calculating lengths\"\"\"\n",
    "            for i in range(0, len(s)-1, 2):\n",
    "                exon_coord = s[i:i+2]\n",
    "                exon_coord.sort()\n",
    "                exon_coord = tuple(exon_coord)\n",
    "                exlen = exon_coord[1]-exon_coord[0]\n",
    "\n",
    "\n",
    "                \"\"\"Quinn Comment: find start position relative to named start of this exon and translate to protein\"\"\"\n",
    "                startpos = (len(leftover)+exlen+1)%3\n",
    "                if strand == '+':\n",
    "                    seq = Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))+leftover \n",
    "                    \"\"\"Quinn Comment: exon length rule\"\"\"\n",
    "                    if exlen + 1 > 407:\n",
    "                        prot = seq[startpos:].translate(stop_symbol = '@')\n",
    "                    else:\n",
    "                        prot = seq[startpos:].translate()\n",
    "                    leftover = seq[:startpos]                                                                                                               \n",
    "                    allprot = prot+allprot  \n",
    "                else:\n",
    "                    seq = leftover+Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))\n",
    "                    aseq = seq\n",
    "                    if startpos > 0:\n",
    "                        leftover = seq[-startpos:]\n",
    "                    else:\n",
    "                        leftover = Seq(\"\")\n",
    "                    seq = seq.reverse_complement()\n",
    "\n",
    "                    if exlen + 1 > 407:\n",
    "                        prot = seq[startpos:].translate(stop_symbol = '@')\n",
    "                    else:\n",
    "                        prot = seq[startpos:].translate()\n",
    "                    \n",
    "                    allprot = prot+allprot\n",
    "\n",
    "                #found a PTC in this transcript if any element but the last is a stop codon    \n",
    "                bool_ptc = \"*\" in allprot[:-1]\n",
    "                bool_long_exon = '@' in allprot[:-1]\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"Quinn Comment: if we found a PTC, add all intron coordinate pairs involved in the transcript to junc_fail\"\"\"        \n",
    "        if bool_ptc:\n",
    "            #This transcript failed\n",
    "            for i in range(1, len(s)-1, 2):                                                                                                                  \n",
    "                j_coord = s[i:i+2]                                                                                                                           \n",
    "                j_coord.sort()                                                                                                                             \n",
    "                j_coord = tuple(j_coord)                                                                                                                     \n",
    "                if j_coord not in junc_fail:                                                                                                                 \n",
    "                    junc_fail[j_coord] = 0                                                                                                                   \n",
    "                junc_fail[j_coord] += 1  \n",
    "\n",
    "            continue\n",
    "    \n",
    "        # passed\n",
    "        \"\"\"Quinn Comment: if we don't just have a stop codon, create a terminus for this \n",
    "        seed at the last 3' splice site or start codon; terminus is last two coordinates and the reading frame, \n",
    "        used for dynamic programming later\"\"\"\n",
    "        if len(s) > 2:\n",
    "            terminus = (s[-2],s[-1],leftover)\n",
    "            \n",
    "            if not bool_long_exon:\n",
    "                if terminus in dic_terminus['normal']:\n",
    "                    dic_terminus['normal'][terminus].append(tuple(s))\n",
    "                    continue\n",
    "                else:\n",
    "                    dic_terminus['normal'][terminus] = [tuple(s)]\n",
    "            else:\n",
    "                if terminus in dic_terminus['long_exon']:\n",
    "                    dic_terminus['long_exon'][terminus].append(tuple(s))\n",
    "                    continue\n",
    "                else:\n",
    "                    dic_terminus['long_exon'][terminus] = [tuple(s)]\n",
    "        \n",
    "        last_pos = s[-1]\n",
    "        \n",
    "        \"\"\"Quinn Comment: check the last position of our seed to see if it is close to a start codon, within a potential exon's length,\n",
    "            and add your seed plus this start codon to final_check \"\"\"\n",
    "        for start in start_codons:                \n",
    "            #print(\"start\", start, abs(last_pos-start[0]))\n",
    "            if strand == \"+\" and last_pos > start[0] and abs(last_pos-start[0]) < exonLcutoff:\n",
    "                final_check.append(s+[start[0]])\n",
    "            elif strand == \"-\" and last_pos < start[1] and abs(last_pos-start[1]) < exonLcutoff:\n",
    "                final_check.append(s+[start[1]]) \n",
    "\n",
    "        \"\"\"Quinn Comment: add all possible places to go from our last_pos to the seed (nested list)\"\"\"\n",
    "        for j0,j1 in junc:                \n",
    "            if strand == \"+\" and last_pos > j1 and abs(last_pos-j1) < exonLcutoff:\n",
    "                new_seed.append(s+[j1,j0])\n",
    "            #print(\"junction\", (j0,j1), abs(last_pos-j0))\n",
    "            if strand == \"-\" and last_pos < j0 and abs(last_pos-j0) < exonLcutoff: \n",
    "                new_seed.append(s+[j0,j1])\n",
    "                \n",
    "    \"\"\"Quinn Comment: Exited from s in seed loop, now we check our final_checks of the full paths, we do not\n",
    "    eliminate paths based on presence of a PTC, rather we classify full complete paths without PTCs if they exist\"\"\"\n",
    "    # check that the possible final paths are good\n",
    "    for s in final_check:\n",
    "        leftover = Seq(\"\")\n",
    "        allprot = Seq(\"\")\n",
    "        for i in range(0, len(s)-1, 2):\n",
    "            exon_coord = s[i:i+2]\n",
    "            exon_coord.sort()\n",
    "            exon_coord = tuple(exon_coord)\n",
    "            exlen = exon_coord[1]-exon_coord[0]\n",
    "            startpos = (len(leftover)+exlen+1)%3\n",
    "            if strand == \"+\":\n",
    "                seq = Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))+leftover\n",
    "                leftover = seq[:startpos]  \n",
    "                if exlen + 1 > 407:\n",
    "                    prot = seq[startpos:].translate(stop_symbol = '@')\n",
    "                else:\n",
    "                    prot = seq[startpos:].translate()\n",
    "                allprot = prot+allprot\n",
    "            else:\n",
    "                seq = leftover+Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))\n",
    "                if startpos > 0:                                                                                                    \n",
    "                    leftover = seq[-startpos:]                                    \n",
    "                else:\n",
    "                    leftover = Seq(\"\")\n",
    "                seq = seq.reverse_complement()                                                                                                           \n",
    "                if exlen + 1 > 407:\n",
    "                    prot = seq[startpos:].translate(stop_symbol = '@')\n",
    "                else:\n",
    "                    prot = seq[startpos:].translate()                                                                                                       \n",
    "                allprot = prot+allprot                    \n",
    "        bool_ptc = \"*\" in allprot[:-1]\n",
    "        bool_long_exon = '@' in allprot[:-1]\n",
    "    \n",
    "        \"\"\"Quinn Comment: Classify seed + start codon as a passing path if no PTCs found in previous block of code\"\"\"\n",
    "        if not bool_ptc:\n",
    "            # all pass\n",
    "            proteins.append(\"\\t\".join([gene_name,chrom,strand, \"-\".join([str(x) for x in s]), str(allprot)])+'\\n')\n",
    "            #print(\"ALL PASS %s\"%(s))\n",
    "            if bool_long_exon:\n",
    "                print('long_exon:')\n",
    "                print(allprot)\n",
    "                path_pass['long_exon'].append(tuple(s))\n",
    "            else:\n",
    "                print('normal:')\n",
    "                print(allprot)\n",
    "                path_pass['normal'].append(tuple(s))\n",
    "            for i in range(1, len(s), 2):\n",
    "                j_coord = s[i:i+2]\n",
    "                j_coord.sort()\n",
    "                j_coord = tuple(j_coord)\n",
    "                if not bool_long_exon: \n",
    "                    if j_coord not in junc_pass['normal']:\n",
    "                        junc_pass['normal'][j_coord] = 0\n",
    "                    junc_pass['normal'][j_coord] += 1\n",
    "                else:\n",
    "                    if j_coord not in junc_pass['long_exon']:\n",
    "                        junc_pass['long_exon'][j_coord] = 0\n",
    "                    junc_pass['long_exon'][j_coord] += 1\n",
    "\n",
    "    seed = new_seed\n",
    "\n",
    "\n",
    "\"\"\"Quinn Comment: OUT OF WHILE LOOP through all possible paths/seeds; \n",
    "check all termini to see if they are part of a full path that has been classified as passing\"\"\"\n",
    "while True:\n",
    "    new_paths = []\n",
    "    for terminus in dic_terminus['normal']:\n",
    "        terminus_pass = False\n",
    "        for path_subset in dic_terminus['normal'][terminus]:\n",
    "            for path in path_pass['normal']:\n",
    "                if path[:len(path_subset)] == path_subset:\n",
    "                    terminus_pass = True\n",
    "                    break\n",
    "        #print(terminus, terminus_pass)\n",
    "\n",
    "        \"\"\"Quinn Comment: if our terminus is part of a passing path, we want to make sure if is reflected in passing paths and\n",
    "        add the associate junctions to junc_pass, only if they are not present\"\"\"\n",
    "        if terminus_pass:\n",
    "            subsets_to_check = dic_terminus['normal'][terminus]\n",
    "            for path_subset in subsets_to_check:\n",
    "                if path_subset in path_pass['normal']: continue\n",
    "                new_paths.append(path_subset)\n",
    "                path_pass['normal'].append(path_subset)\n",
    "                for i in range(1, len(path_subset), 2):\n",
    "                    j_coord = list(path_subset[i:i+2])\n",
    "                    j_coord.sort()\n",
    "                    j_coord = tuple(j_coord)\n",
    "                    if j_coord not in junc_pass['normal']:\n",
    "                        junc_pass['normal'][j_coord] = 0\n",
    "                        if verbose:\n",
    "                            sys.stdout.write(\"junction pass:\" + str(j_coord))\n",
    "\n",
    "    \"\"\"Quinn Comment: we could have a new path_pass added, so our while loop checks again to see if there are any new paths \n",
    "    that are now going to be passing considering our additions\"\"\"\n",
    "    if len(new_paths) == 0:\n",
    "        break\n",
    "\n",
    "\n",
    "while True:\n",
    "    new_paths = []\n",
    "    for terminus in dic_terminus['long_exon']:\n",
    "        terminus_pass = False\n",
    "        for path_subset in dic_terminus['long_exon'][terminus]:\n",
    "            for path in path_pass['long_exon']:\n",
    "                if path[:len(path_subset)] == path_subset:\n",
    "                    terminus_pass = True\n",
    "                    break\n",
    "        #print(terminus, terminus_pass)\n",
    "\n",
    "        \"\"\"Quinn Comment: if our terminus is part of a passing path, we want to make sure if is reflected in passing paths and\n",
    "        add the associate junctions to junc_pass, only if they are not present\"\"\"\n",
    "        if terminus_pass:\n",
    "            subsets_to_check = dic_terminus['long_exon'][terminus]\n",
    "            for path_subset in subsets_to_check:\n",
    "                if path_subset in path_pass['long_exon']: continue\n",
    "                new_paths.append(path_subset)\n",
    "                path_pass['long_exon'].append(path_subset)\n",
    "                for i in range(1, len(path_subset), 2):\n",
    "                    j_coord = list(path_subset[i:i+2])\n",
    "                    j_coord.sort()\n",
    "                    j_coord = tuple(j_coord)\n",
    "                    if j_coord not in junc_pass['long_exon']:\n",
    "                        junc_pass['long_exon'][j_coord] = 0\n",
    "                        if verbose:\n",
    "                            sys.stdout.write(\"junction long_exon:\" + str(j_coord))\n",
    "\n",
    "    \"\"\"Quinn Comment: we could have a new path_pass added, so our while loop checks again to see if there are any new paths \n",
    "    that are now going to be passing considering our additions\"\"\"\n",
    "    if len(new_paths) == 0:\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normal': {(1490671, 1495485): 2,\n",
       "  (1490424, 1490563): 2,\n",
       "  (1489274, 1490257): 2,\n",
       "  (1487914, 1489204): 2,\n",
       "  (1486668, 1487863): 2,\n",
       "  (1486235, 1486544): 2,\n",
       "  (1485838, 1486110): 2,\n",
       "  (1485171, 1485782): 2,\n",
       "  (1482614, 1485016): 2,\n",
       "  (1482303, 1482545): 2,\n",
       "  (1480936, 1482138): 2,\n",
       "  (1477350, 1480867): 2,\n",
       "  (1472306, 1477274): 1,\n",
       "  (1471885,): 2,\n",
       "  (1472089, 1477274): 1},\n",
       " 'long_exon': {(1490671, 1495485): 3,\n",
       "  (1489811, 1490257): 3,\n",
       "  (1486668, 1489204): 3,\n",
       "  (1485838, 1486110): 3,\n",
       "  (1482614, 1485016): 3,\n",
       "  (1480936, 1482138): 3,\n",
       "  (1477350, 1480867): 2,\n",
       "  (1472306, 1477274): 2,\n",
       "  (1471885,): 3,\n",
       "  (1472089, 1477274): 1,\n",
       "  (1479108, 1480867): 1,\n",
       "  (1478745, 1479049): 1,\n",
       "  (1477350, 1477751): 1,\n",
       "  (1489274, 1490257): 0,\n",
       "  (1490424, 1490563): 0,\n",
       "  (1485171, 1485782): 0,\n",
       "  (1487914, 1489204): 0,\n",
       "  (1486668, 1487863): 0,\n",
       "  (1482303, 1482545): 0,\n",
       "  (1480908, 1482266): 0,\n",
       "  (1477350, 1478644): 0,\n",
       "  (1478351, 1478644): 0,\n",
       "  (1486235, 1486544): 0}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junc_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'normal': [],\n",
       " 'long_exon': [(1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1477350,\n",
       "   1477274,\n",
       "   1472306,\n",
       "   1471885),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1477350,\n",
       "   1477274,\n",
       "   1472089,\n",
       "   1471885),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1479108,\n",
       "   1479049,\n",
       "   1478745,\n",
       "   1477751,\n",
       "   1477350,\n",
       "   1477274,\n",
       "   1472306,\n",
       "   1471885),\n",
       "  (1495817, 1495485, 1490671),\n",
       "  (1495817, 1495485, 1490671, 1490257, 1489811),\n",
       "  (1495817, 1495485, 1490671, 1490563, 1490424, 1490257, 1489811),\n",
       "  (1495817, 1495485, 1490671, 1490257, 1489811, 1489204, 1486668),\n",
       "  (1495817, 1495485, 1490671, 1490257, 1489274, 1489204, 1486668),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1485782,\n",
       "   1485171,\n",
       "   1485016,\n",
       "   1482614),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482545,\n",
       "   1482303,\n",
       "   1482138,\n",
       "   1480936),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482545,\n",
       "   1482303),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1479108),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482545,\n",
       "   1482303,\n",
       "   1482266,\n",
       "   1480908,\n",
       "   1480867,\n",
       "   1479108),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1477350),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482545,\n",
       "   1482303,\n",
       "   1482266,\n",
       "   1480908,\n",
       "   1480867,\n",
       "   1477350),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482545,\n",
       "   1482303,\n",
       "   1482266,\n",
       "   1480908),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1479108,\n",
       "   1479049,\n",
       "   1478745),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1477350,\n",
       "   1477274,\n",
       "   1472306),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1479108,\n",
       "   1478644,\n",
       "   1477350,\n",
       "   1477274,\n",
       "   1472306),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1477350,\n",
       "   1477274,\n",
       "   1472089),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1479108,\n",
       "   1478644,\n",
       "   1477350,\n",
       "   1477274,\n",
       "   1472089),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1479108,\n",
       "   1479049,\n",
       "   1478745,\n",
       "   1477751,\n",
       "   1477350),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1479108,\n",
       "   1478644,\n",
       "   1478351,\n",
       "   1477751,\n",
       "   1477350),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1479108,\n",
       "   1479049,\n",
       "   1478745,\n",
       "   1477751,\n",
       "   1477350,\n",
       "   1477274,\n",
       "   1472306),\n",
       "  (1495817, 1495485, 1490671, 1490563, 1490424),\n",
       "  (1495817, 1495485, 1490671, 1490257, 1489274),\n",
       "  (1495817, 1495485, 1490671, 1490563, 1490424, 1490257, 1489274),\n",
       "  (1495817, 1495485, 1490671, 1490257, 1489811, 1489204, 1487914),\n",
       "  (1495817, 1495485, 1490671, 1490257, 1489274, 1489204, 1487914),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1485782,\n",
       "   1485171),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1485782,\n",
       "   1485171,\n",
       "   1485016,\n",
       "   1482614),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1479108),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1479108,\n",
       "   1478644,\n",
       "   1477350),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1479108,\n",
       "   1479049,\n",
       "   1478745,\n",
       "   1478644,\n",
       "   1477350),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485016,\n",
       "   1482614,\n",
       "   1482138,\n",
       "   1480936,\n",
       "   1480867,\n",
       "   1479108,\n",
       "   1478644,\n",
       "   1478351),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1485782,\n",
       "   1485171),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486544,\n",
       "   1486235,\n",
       "   1486110,\n",
       "   1485838,\n",
       "   1485782,\n",
       "   1485171),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486544,\n",
       "   1486235,\n",
       "   1486110,\n",
       "   1485838),\n",
       "  (1495817,\n",
       "   1495485,\n",
       "   1490671,\n",
       "   1490257,\n",
       "   1489811,\n",
       "   1489204,\n",
       "   1487914,\n",
       "   1487863,\n",
       "   1486668,\n",
       "   1486544,\n",
       "   1486235)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
