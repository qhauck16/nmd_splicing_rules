{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gzip\n",
    "import argparse\n",
    "import pickle\n",
    "from statistics import mean, median\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "import pyfastx\n",
    "\n",
    "\n",
    "\n",
    "chrom = 'chr1'\n",
    "strand = '-'\n",
    "junc = [(1395537, 1398233), (1389477, 1390230), (1388743, 1388816), (1388743, 1390230), (1388065, 1390230), (1388743, 1388950), (1398342, 1398597), (1387869, 1387954), (1387582, 1387777), (1391553, 1392679), (1388065, 1388950), (1391575, 1392679), (1398418, 1398597), (1390865, 1392679), (1390865, 1391297), (1393460, 1395394), (1390865, 1393396), (1388510, 1388626), (1388065, 1388492), (1391575, 1392790), (1392803, 1393396), (1390309, 1390315), (1388065, 1388626), (1398671, 1399019), (1390371, 1390459), (1395514, 1398233), (1390865, 1392790), (1389473, 1390230), (1390563, 1390766), (1398671, 1398988), (1389047, 1390230), (1388830, 1390230)]\n",
    "start_codons = {(1398663, 1398665), (1399304, 1399306), (1390856, 1390858)}\n",
    "stop_codons = {(1387231, 1387233), (1392782, 1392784)}\n",
    "gene_name = 'CCNL2'\n",
    "exonLcutoff=1000\n",
    "verbose=True\n",
    "fa = pyfastx.Fasta('genome.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 1, Seed L = 2\n",
      "Depth 2, Seed L = 8\n",
      "Depth 3, Seed L = 46\n",
      "Depth 4, Seed L = 116\n",
      "Depth 5, Seed L = 107\n",
      "Depth 6, Seed L = 51\n",
      "Depth 7, Seed L = 53\n",
      "Depth 8, Seed L = 8\n",
      "Depth 9, Seed L = 6\n",
      "junction pass:(1390865, 1393396)\n",
      "junction pass:(1388065, 1388950)\n",
      "junction pass:(1389047, 1390230)\n",
      "junction pass:(1390309, 1390315)\n",
      "junction pass:(1388065, 1388492)\n",
      "junction pass:(1388510, 1388626)\n",
      "junction pass:(1388743, 1390230)\n",
      "junction pass:(1388830, 1390230)\n",
      "junction pass:(1388743, 1388816)\n",
      "junction long_exon:(1388743, 1388816)\n",
      "junction long_exon:(1390865, 1392790)\n",
      "junction long_exon:(1390865, 1391297)\n",
      "junction long_exon:(1391575, 1392679)\n",
      "junction long_exon:(1391575, 1392790)\n",
      "junction long_exon:(1390865, 1393396)\n"
     ]
    }
   ],
   "source": [
    "junc_pass, junc_fail, proteins = solve_NMD(chrom, strand, junc, start_codons, stop_codons,gene_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptc_pos_from_prot(prot, sub):\n",
    "    to_return = []\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = prot.find(sub, start)\n",
    "        if start == -1: return to_return\n",
    "        else:\n",
    "            to_return.append(start)\n",
    "        start += 1   \n",
    "   \n",
    "\n",
    "def check_utrs(junc,utrs):\n",
    "    '''\n",
    "    checks if junction is close or within 100bp of UTRs\n",
    "    '''\n",
    "    for s1,s2 in list(utrs):\n",
    "        if abs(junc[0]-s1) < 100 or abs(junc[1]-s2) < 100:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def solve_NMD(chrom, strand, junc, start_codons, stop_codons,gene_name, \n",
    "              verbose = True, exonLcutoff = 1000):\n",
    "    '''\n",
    "    Compute whether there is a possible combination that uses the junction without\n",
    "    inducing a PTC. We start with all annotated stop codon and go backwards.\n",
    "    '''\n",
    "    \n",
    "    global fa\n",
    "    \n",
    "    seed = []\n",
    "\n",
    "    junc.sort()\n",
    "    if strand == \"+\":\n",
    "        junc.reverse()\n",
    "        \n",
    "    \"\"\"Quinn Comment: Adds all 'stop codons' to a nested list called seed\"\"\" \n",
    "    ##in an individual transcript    \n",
    "    for c in stop_codons:\n",
    "        if strand == \"+\":\n",
    "            seed.append([c[1]])\n",
    "        else:\n",
    "            seed.append([c[0]])\n",
    "\n",
    "    # seed starts with just stop codon and then a possible 3'ss-5'ss junction\n",
    "    # without introducing a PTC [stop_codon,3'ss, 5'ss, 3'ss, ..., start_codon]\n",
    "\n",
    "    junc_pass = {'normal':{}, 'long_exon':{}}\n",
    "    junc_fail = {}\n",
    "    path_pass = {'normal':[], 'long_exon':[]}\n",
    "    proteins = []\n",
    "    short_ptcs = {}\n",
    "\n",
    "    dic_terminus = {'normal': {}, 'long_exon': {}}\n",
    "\n",
    "    depth = 0\n",
    "\n",
    "    \"\"\"Quinn Comment: while our seed length is greater than 0 - which means we have charted all possible paths through \n",
    "    all junctions ending in a stop codon (or there is an exon longer than 1000 bp and we have no complete paths)\"\"\"\n",
    "    while len(seed) > 0:\n",
    "        new_seed = []\n",
    "        final_check = []\n",
    "        depth += 1\n",
    "        if verbose:\n",
    "            sys.stdout.write(\"Depth %s, Seed L = %s\\n\"%(depth, len(seed)))\n",
    "        #print(start_codons, [s[-1] for s in seed][-10:], len(junc))\n",
    "        framepos = {}\n",
    "                    \n",
    "        for s in seed:\n",
    "            # first check that the seed paths are good        \n",
    "            bool_ptc = False\n",
    "            leftover = ''\n",
    "            if len(s) > 0:                \n",
    "                leftover = Seq(\"\")\n",
    "                allprot = Seq(\"\")\n",
    "\n",
    "                \"\"\"Quinn Comment: loop through the exons, calculating lengths\"\"\"\n",
    "                for i in range(0, len(s)-1, 2):\n",
    "                    exon_coord = s[i:i+2]\n",
    "                    exon_coord.sort()\n",
    "                    exon_coord = tuple(exon_coord)\n",
    "                    exlen = exon_coord[1]-exon_coord[0]\n",
    "\n",
    "\n",
    "                    \"\"\"Quinn Comment: find start position relative to named start of this exon and translate to protein\"\"\"\n",
    "                    startpos = (len(leftover)+exlen+1)%3\n",
    "                    if strand == '+':\n",
    "                        seq = Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))+leftover \n",
    "                        \"\"\"Quinn Comment: exon length rule\"\"\"\n",
    "                        if exlen + 1 > 407:\n",
    "                            prot = seq[startpos:].translate(stop_symbol = '@')\n",
    "                        else:\n",
    "                            prot = seq[startpos:].translate()\n",
    "\n",
    "                            #store ptc position for checking with long_exon PTCs later\n",
    "                            ptc_pos = ptc_pos_from_prot(prot, '*')\n",
    "                            ptc_coord = [exon_coord[1] - (x+1)*3 - len(leftover) for x in ptc_pos]\n",
    "                            \n",
    "                            #don't want to keep the actual stop codon\n",
    "                            if i == 0 and len(ptc_coord) > 0: ptc_coord.pop(-1)\n",
    "                            for k in ptc_coord:\n",
    "                                short_ptcs[k] = exon_coord\n",
    "                        leftover = seq[:startpos]                                                                                                               \n",
    "                        allprot = prot+allprot  \n",
    "                    else:\n",
    "                        seq = leftover+Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))\n",
    "                        if startpos > 0:\n",
    "                            leftover = seq[-startpos:]\n",
    "                        else:\n",
    "                            leftover = Seq(\"\")\n",
    "                        seq = seq.reverse_complement()\n",
    "\n",
    "                        if exlen + 1 > 407:\n",
    "                            prot = seq[startpos:].translate(stop_symbol = '@')\n",
    "                        else:\n",
    "                            prot = seq[startpos:].translate()\n",
    "                            ptc_pos = ptc_pos_from_prot(prot, '*')\n",
    "                            ptc_coord = [exon_coord[0] + (x+1)*3 - len(leftover) for x in ptc_pos]\n",
    "                            if i == 0 and len(ptc_coord) > 0: ptc_coord.pop(-1)\n",
    "                            for k in ptc_coord:\n",
    "                                short_ptcs[k] = exon_coord\n",
    "                        \n",
    "                        allprot = prot+allprot\n",
    "\n",
    "                    #found a PTC in this transcript if any element but the last is a stop codon    \n",
    "                    bool_ptc = \"*\" in allprot[:-1]\n",
    "                    bool_long_exon = '@' in allprot[:-1]\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "            \"\"\"Quinn Comment: if we found a PTC, add all intron coordinate pairs involved in the transcript to junc_fail\"\"\"        \n",
    "            if bool_ptc:\n",
    "                #This transcript failed\n",
    "                for i in range(1, len(s)-1, 2):                                                                                                                  \n",
    "                    j_coord = s[i:i+2]                                                                                                                           \n",
    "                    j_coord.sort()                                                                                                                             \n",
    "                    j_coord = tuple(j_coord)                                                                                                                     \n",
    "                    if j_coord not in junc_fail:                                                                                                                 \n",
    "                        junc_fail[j_coord] = 0                                                                                                                   \n",
    "                    junc_fail[j_coord] += 1  \n",
    "\n",
    "                continue\n",
    "        \n",
    "            # passed\n",
    "            \"\"\"Quinn Comment: if we don't just have a stop codon, create a terminus for this \n",
    "            seed at the last 3' splice site or start codon; terminus is last two coordinates and the reading frame, \n",
    "            used for dynamic programming later\"\"\"\n",
    "            if len(s) > 2:\n",
    "                terminus = (s[-2],s[-1],leftover)\n",
    "                \n",
    "                if not bool_long_exon:\n",
    "                    if terminus in dic_terminus['normal']:\n",
    "                        dic_terminus['normal'][terminus].append(tuple(s))\n",
    "                        continue\n",
    "                    else:\n",
    "                        dic_terminus['normal'][terminus] = [tuple(s)]\n",
    "                else:\n",
    "                    if terminus in dic_terminus['long_exon']:\n",
    "                        dic_terminus['long_exon'][terminus].append(tuple(s))\n",
    "                        continue\n",
    "                    else:\n",
    "                        dic_terminus['long_exon'][terminus] = [tuple(s)]\n",
    "            \n",
    "            last_pos = s[-1]\n",
    "            \n",
    "            #remove any termini that rely on a long_exon PTC that is also a short exon PTC\n",
    "            for k in dic_terminus['long_exon']:\n",
    "                to_remove = []\n",
    "                for v in dic_terminus['long_exon'][k]:\n",
    "                    if len(v) < 2: continue\n",
    "                    for j in range(0, len(v)-1, 2):\n",
    "                        exon_coord = [v[j], v[j+1]]\n",
    "                        exon_coord.sort()\n",
    "                        exon_coord = tuple(exon_coord)\n",
    "                        if exon_coord in short_ptcs.values():\n",
    "                            to_remove.append(v)\n",
    "                            break\n",
    "                for rem in to_remove:\n",
    "                    dic_terminus['long_exon'][k].remove(rem)\n",
    "\n",
    "            \"\"\"Quinn Comment: check the last position of our seed to see if it is close to a start codon, within a potential exon's length,\n",
    "            and add your seed plus this start codon to final_check \"\"\"\n",
    "            for start in start_codons:                \n",
    "                #print(\"start\", start, abs(last_pos-start[0]))\n",
    "                if strand == \"+\" and last_pos > start[0] and abs(last_pos-start[0]) < exonLcutoff:\n",
    "                    final_check.append(s+[start[0]])\n",
    "                elif strand == \"-\" and last_pos < start[1] and abs(last_pos-start[1]) < exonLcutoff:\n",
    "                    final_check.append(s+[start[1]]) \n",
    "\n",
    "            \"\"\"Quinn Comment: add all possible places to go from our last_pos to the seed (nested list)\"\"\"\n",
    "            for j0,j1 in junc:                \n",
    "                if strand == \"+\" and last_pos > j1 and abs(last_pos-j1) < exonLcutoff:\n",
    "                    new_seed.append(s+[j1,j0])\n",
    "                #print(\"junction\", (j0,j1), abs(last_pos-j0))\n",
    "                if strand == \"-\" and last_pos < j0 and abs(last_pos-j0) < exonLcutoff: \n",
    "                    new_seed.append(s+[j0,j1])\n",
    "                    \n",
    "        \"\"\"Quinn Comment: Exited from s in seed loop, now we check our final_checks of the full paths, we do not\n",
    "        eliminate paths based on presence of a PTC, rather we classify full complete paths without PTCs if they exist\"\"\"\n",
    "        # check that the possible final paths are good\n",
    "        for s in final_check:\n",
    "            leftover = Seq(\"\")\n",
    "            allprot = Seq(\"\")\n",
    "            for i in range(0, len(s)-1, 2):\n",
    "                exon_coord = s[i:i+2]\n",
    "                exon_coord.sort()\n",
    "                exon_coord = tuple(exon_coord)\n",
    "                exlen = exon_coord[1]-exon_coord[0]\n",
    "                startpos = (len(leftover)+exlen+1)%3\n",
    "                if strand == \"+\":\n",
    "                    seq = Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))+leftover\n",
    "                    leftover = seq[:startpos]  \n",
    "                    if exlen + 1 > 407:\n",
    "                        prot = seq[startpos:].translate(stop_symbol = '@')\n",
    "                        #only allow long_exon tag to persist if PTCs introduced are solely present in a long exon \n",
    "                        ptc_pos = ptc_pos_from_prot(prot, '@')\n",
    "                        ptc_coord = [exon_coord[1] - (i+1)*3 - len(leftover) for i in ptc_pos]\n",
    "                        check = [i in short_ptcs.keys() for i in ptc_coord]\n",
    "                        if sum(check) > 0:\n",
    "                            prot = seq[startpos:].translate()\n",
    "                    else:\n",
    "                        prot = seq[startpos:].translate()\n",
    "                    allprot = prot+allprot\n",
    "                else:\n",
    "                    seq = leftover+Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))\n",
    "                    if startpos > 0:                                                                                                    \n",
    "                        leftover = seq[-startpos:]                                    \n",
    "                    else:\n",
    "                        leftover = Seq(\"\")\n",
    "                    seq = seq.reverse_complement()                                                                                                           \n",
    "                    if exlen + 1 > 407:\n",
    "                        prot = seq[startpos:].translate(stop_symbol = '@')\n",
    "                        ptc_pos = ptc_pos_from_prot(prot, '@')\n",
    "                        ptc_coord = [exon_coord[0] + (i+1)*3 - len(leftover) for i in ptc_pos]\n",
    "                        check = [i in short_ptcs.keys() for i in ptc_coord]\n",
    "                        if sum(check) > 0:\n",
    "                            prot = seq[startpos:].translate()\n",
    "                    else:\n",
    "                        prot = seq[startpos:].translate()                                                                                                       \n",
    "                    allprot = prot+allprot                    \n",
    "            bool_ptc = \"*\" in allprot[:-1]\n",
    "            bool_long_exon = '@' in allprot[:-1]\n",
    "        \n",
    "            \"\"\"Quinn Comment: Classify seed + start codon as a passing path if no PTCs found in previous block of code\"\"\"\n",
    "            if not bool_ptc:\n",
    "                # all pass\n",
    "                proteins.append(\"\\t\".join([gene_name,chrom,strand, \"-\".join([str(x) for x in s]), str(allprot)])+'\\n')\n",
    "                #print(\"ALL PASS %s\"%(s))\n",
    "                if bool_long_exon:\n",
    "                    path_pass['long_exon'].append(tuple(s))\n",
    "                else:\n",
    "                    path_pass['normal'].append(tuple(s))\n",
    "                for i in range(1, len(s), 2):\n",
    "                    j_coord = s[i:i+2]\n",
    "                    j_coord.sort()\n",
    "                    j_coord = tuple(j_coord)\n",
    "                    if not bool_long_exon: \n",
    "                        if j_coord not in junc_pass['normal']:\n",
    "                            junc_pass['normal'][j_coord] = 0\n",
    "                        junc_pass['normal'][j_coord] += 1\n",
    "                    else:\n",
    "                        if j_coord not in junc_pass['long_exon']:\n",
    "                            junc_pass['long_exon'][j_coord] = 0\n",
    "                        junc_pass['long_exon'][j_coord] += 1\n",
    "\n",
    "        seed = new_seed\n",
    "\n",
    "\n",
    "    \"\"\"Quinn Comment: OUT OF WHILE LOOP through all possible paths/seeds; \n",
    "    check all termini to see if they are part of a full path that has been classified as passing\"\"\"\n",
    "    while True:\n",
    "        new_paths = []\n",
    "        for terminus in dic_terminus['normal']:\n",
    "            terminus_pass = False\n",
    "            for path_subset in dic_terminus['normal'][terminus]:\n",
    "                for path in path_pass['normal']:\n",
    "                    if path[:len(path_subset)] == path_subset:\n",
    "                        terminus_pass = True\n",
    "                        break\n",
    "            #print(terminus, terminus_pass)\n",
    "\n",
    "            \"\"\"Quinn Comment: if our terminus is part of a passing path, we want to make sure if is reflected in passing paths and\n",
    "            add the associate junctions to junc_pass, only if they are not present\"\"\"\n",
    "            if terminus_pass:\n",
    "                subsets_to_check = dic_terminus['normal'][terminus]\n",
    "                for path_subset in subsets_to_check:\n",
    "                    if path_subset in path_pass['normal']: continue\n",
    "                    new_paths.append(path_subset)\n",
    "                    path_pass['normal'].append(path_subset)\n",
    "                    for i in range(1, len(path_subset), 2):\n",
    "                        j_coord = list(path_subset[i:i+2])\n",
    "                        j_coord.sort()\n",
    "                        j_coord = tuple(j_coord)\n",
    "                        if j_coord not in junc_pass['normal']:\n",
    "                            junc_pass['normal'][j_coord] = 0\n",
    "                            if verbose:\n",
    "                                sys.stdout.write(\"junction pass:\" + str(j_coord) + '\\n')\n",
    "\n",
    "        \"\"\"Quinn Comment: we could have a new path_pass added, so our while loop checks again to see if there are any new paths \n",
    "        that are now going to be passing considering our additions\"\"\"\n",
    "        if len(new_paths) == 0:\n",
    "            break\n",
    "\n",
    "    #Now do the same for the long_exon termini and paths\n",
    "    #We do not care if a terminus is long_exon or not, as long as it ends up leading to a long_exon path\n",
    "    combined_keys = dic_terminus['long_exon'].keys() | dic_terminus['normal'].keys()\n",
    "    combined_termini = {key: dic_terminus['long_exon'].get(key, []) + dic_terminus['normal'].get(key, []) for key in combined_keys}  \n",
    "    while True:\n",
    "        new_paths = []\n",
    "        for terminus in combined_termini:\n",
    "            terminus_pass = False\n",
    "            for path_subset in combined_termini[terminus]:\n",
    "                for path in path_pass['long_exon']:\n",
    "                    if path[:len(path_subset)] == path_subset:\n",
    "                        terminus_pass = True\n",
    "                        break\n",
    "            #print(terminus, terminus_pass)\n",
    "\n",
    "            \"\"\"Quinn Comment: if our terminus is part of a passing path, we want to make sure if is reflected in passing paths and\n",
    "            add the associate junctions to junc_pass, only if they are not present\"\"\"\n",
    "            if terminus_pass:\n",
    "                subsets_to_check = combined_termini[terminus]\n",
    "                for path_subset in subsets_to_check:\n",
    "                    if path_subset in path_pass['long_exon']: continue\n",
    "                    new_paths.append(path_subset)\n",
    "                    path_pass['long_exon'].append(path_subset)\n",
    "                    for i in range(1, len(path_subset), 2):\n",
    "                        j_coord = list(path_subset[i:i+2])\n",
    "                        j_coord.sort()\n",
    "                        j_coord = tuple(j_coord)\n",
    "                        if j_coord not in junc_pass['long_exon']:\n",
    "                            junc_pass['long_exon'][j_coord] = 0\n",
    "                            if verbose:\n",
    "                                sys.stdout.write(\"junction long_exon:\" + str(j_coord) + '\\n')\n",
    "\n",
    "        \"\"\"Quinn Comment: we could have a new path_pass added, so our while loop checks again to see if there are any new paths \n",
    "        that are now going to be passing considering our additions\"\"\"\n",
    "        if len(new_paths) == 0:\n",
    "            break\n",
    "            \n",
    "    return junc_pass, junc_fail, proteins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
