{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gzip\n",
    "import argparse\n",
    "import pickle\n",
    "from statistics import mean, median\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "import pyfastx\n",
    "\n",
    "global fa\n",
    "fa = pyfastx.Fasta('/project2/yangili1/qhauck/nmd_splicing_rules/testing_new_rules/testing_long_exon/genome.fa')\n",
    "chrom = 'chr1'\n",
    "strand = '-'\n",
    "junc = [(1395537, 1398233), (1389477, 1390230), (1388743, 1388816), (1388743, 1390230), (1388065, 1390230), (1388743, 1388950), (1398342, 1398597), (1387869, 1387954), (1387582, 1387777), (1391553, 1392679), (1388065, 1388950), (1391575, 1392679), (1398418, 1398597), (1390865, 1392679), (1390865, 1391297), (1393460, 1395394), (1390865, 1393396), (1388510, 1388626), (1388065, 1388492), (1391575, 1392790), (1392803, 1393396), (1390309, 1390315), (1388065, 1388626), (1398671, 1399019), (1390371, 1390459), (1395514, 1398233), (1390865, 1392790), (1389473, 1390230), (1390563, 1390766), (1398671, 1398988), (1389047, 1390230), (1388830, 1390230)]\n",
    "start_codons = {(1398663, 1398665), (1399304, 1399306), (1390856, 1390858)}\n",
    "stop_codons = {(1387231, 1387233), (1392782, 1392784)}\n",
    "gene_name = 'CCNL2'\n",
    "exonLcutoff=1000\n",
    "verbose=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_exon_finder(failing_juncs, gene_name, transcripts_by_gene, strand, chrom):\n",
    "    long_exons = []\n",
    "    for junc in failing_juncs:\n",
    "        junc_added = False\n",
    "        possible_transcripts = transcripts_by_gene[gene_name]\n",
    "        for transcript in possible_transcripts:\n",
    "            s = list(possible_transcripts[transcript])\n",
    "            #cast to list of integers\n",
    "            s = [eval(j) for j in s]\n",
    "            \n",
    "            if strand == '-':\n",
    "                s.reverse()\n",
    "\n",
    "            new_junc = False\n",
    "            failing_junc = False\n",
    "            for i in range(len(s)-2, 0, -2):\n",
    "                junction = tuple([s[i-1], s[i]])\n",
    "\n",
    "                #overlapping 3' or 5' splice site, just replace the junction\n",
    "                if junc[0] == junction[0] or junc[1] == junction[1]:\n",
    "                    s[i-1] = junc[0]\n",
    "                    s[i] = junc[1]\n",
    "                    new_junc = True\n",
    "                #if this does not fit in our transcript, move on\n",
    "                    if strand == '+' and not (s[i-1] > s[i-2] and s[i] < s[i+1]):\n",
    "                        failing_junc = True\n",
    "                    elif strand == '-' and not (s[i-1] < s[i-2] and s[i] > s[i+1]):\n",
    "                        failing_junc = True\n",
    "                    \n",
    "                    break  \n",
    "\n",
    "            #If our overlapping site configuration fails in the transcript, skip this transcript     \n",
    "            if failing_junc:\n",
    "                continue\n",
    "            \n",
    "            #s.reverse()\n",
    "            allprot = Seq(\"\")\n",
    "            leftover = Seq(\"\")\n",
    "\n",
    "            bool_long_exon = False\n",
    "            for i in range(0, len(s)-1, 2):\n",
    "                exon_coord = s[i:i+2]\n",
    "                exon_coord.sort()\n",
    "                exon_coord = tuple(exon_coord)\n",
    "                exlen = int(exon_coord[1])-int(exon_coord[0])\n",
    "\n",
    "\n",
    "                \"\"\"Quinn Comment: find start position relative to named start of this exon and translate to protein\"\"\"\n",
    "                \"\"\"Quinn Comment: Coordinates from PERIND file and GTF file are exon start and end coordinates, so \n",
    "                we must add 1 to length\"\"\"\n",
    "                endpos = (len(leftover)+exlen+1)%3\n",
    "\n",
    "                if strand == '+':\n",
    "                    seq = leftover + Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))\n",
    "                    prot = seq[:-endpos].translate()\n",
    "                    leftover = seq[-endpos:]                                                                                                               \n",
    "                    \n",
    "                    if i == len(s)-2:\n",
    "                        bool_ptc = \"*\" in prot[:-1]\n",
    "                        ptc_pos = ptc_pos_from_prot(prot[:-1], '*')\n",
    "                    else:\n",
    "                        bool_ptc = \"*\" in prot \n",
    "                        ptc_pos = ptc_pos_from_prot(prot, '*')\n",
    "\n",
    "                    allprot = allprot+prot\n",
    "                else:\n",
    "                    seq = Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1]))) + leftover\n",
    "                    aseq = seq\n",
    "                    if endpos > 0:\n",
    "                        leftover = seq[-endpos:]\n",
    "                    else:\n",
    "                        leftover = Seq(\"\")\n",
    "                    seq = seq.reverse_complement()\n",
    "                    prot = seq[:-endpos].translate()\n",
    "                    print(prot)\n",
    "                    if i == s-2:\n",
    "                        bool_ptc = \"*\" in prot[:-1]\n",
    "                        ptc_pos = ptc_pos_from_prot(prot[:-1], '*')\n",
    "                    else:\n",
    "                        bool_ptc = \"*\" in prot\n",
    "                        ptc_pos = ptc_pos_from_prot(prot, '*')\n",
    "\n",
    "                    allprot = allprot+prot\n",
    "                \n",
    "                #store a long_exon tag, only add this junction to list if it goes on to cause no PTCs that are not in long exons\n",
    "                if bool_ptc and new_junc and i != 0:\n",
    "                    ptc_coords = [exon_coord[0] + endpos + 3*x for x in ptc_pos]\n",
    "                    if exlen+1 > 407:\n",
    "                        long_exons.append(junc)\n",
    "                        junc_added = True\n",
    "                    break\n",
    "            if junc_added:\n",
    "                break\n",
    "    return long_exons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptc_pos_from_prot(prot, sub):\n",
    "    to_return = []\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = prot.find(sub, start)\n",
    "        if start == -1: return to_return\n",
    "        else:\n",
    "            to_return.append(start)\n",
    "        start += 1\n",
    "\n",
    "from bisect import insort\n",
    "gtf_annot = '/project2/yangili1/qhauck/nmd_splicing_rules/add_on_script/gencode.v37.annotation.gtf'\n",
    "\n",
    "\n",
    "junc_pass = set(junc_pass)\n",
    "junc_fail = set(junc_fail)\n",
    "failing_juncs = junc_fail.difference(junc_pass)\n",
    "\n",
    "def tx_by_gene(gtf_annot):\n",
    "    transcripts_by_gene = {}\n",
    "    i = 1\n",
    "    for dic in parse_gtf(gtf_annot):\n",
    "        if dic['type'] == 'transcript':\n",
    "            if dic['gene_name'] not in transcripts_by_gene:\n",
    "                transcripts_by_gene[dic['gene_name']] = {dic['transcript_name']: []}\n",
    "            else:\n",
    "                transcripts_by_gene[dic['gene_name']] = transcripts_by_gene[dic['gene_name']] | {dic['transcript_name']: []}\n",
    "        if dic['type'] == 'start_codon':\n",
    "            insort(transcripts_by_gene[dic['gene_name']][dic['transcript_name']], (dic['end']))\n",
    "        if dic['type'] == 'stop_codon':\n",
    "            insort(transcripts_by_gene[dic['gene_name']][dic['transcript_name']], (dic['start']))\n",
    "        if dic['type'] == 'exon':\n",
    "            insort(transcripts_by_gene[dic['gene_name']][dic['transcript_name']], (dic['start']))\n",
    "            insort(transcripts_by_gene[dic['gene_name']][dic['transcript_name']], (dic['end']))\n",
    "    return transcripts_by_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cd'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'abcd'[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing junction counts /project2/yangili1/qhauck/nmd_splicing_rules/add_on_script/juncs.perind.txt.gz...done!\n",
      "Processed: 17706 jxns on chr1 (-).18342 jxns on chr1 (+).12723 jxns on chr2 (-).13377 jxns on chr2 (+).11103 jxns on chr3 (-).9976 jxns on chr3 (+).7023 jxns on chr4 (+).6675 jxns on chr4 (-).8249 jxns on chr5 (+).7823 jxns on chr5 (-).10048 jxns on chr6 (+).9426 jxns on chr6 (-).8586 jxns on chr7 (-).9824 jxns on chr7 (+).5935 jxns on chr8 (-).6992 jxns on chr8 (+).7325 jxns on chr9 (-).7699 jxns on chr9 (+).7127 jxns on chr10 (+).7021 jxns on chr10 (-).8944 jxns on chr11 (-).9941 jxns on chr11 (+).10343 jxns on chr12 (-).10442 jxns on chr12 (+).3597 jxns on chr13 (-).3458 jxns on chr13 (+).6182 jxns on chr14 (+).6001 jxns on chr14 (-).6996 jxns on chr15 (-).6137 jxns on chr15 (+).7931 jxns on chr16 (-).9325 jxns on chr16 (+).11744 jxns on chr17 (-).10015 jxns on chr17 (+).2932 jxns on chr18 (+).2855 jxns on chr18 (-).10330 jxns on chr19 (-).11025 jxns on chr19 (+).4231 jxns on chr20 (-).4715 jxns on chr20 (+).2718 jxns on chr21 (+).2509 jxns on chr21 (-).4641 jxns on chr22 (+).4551 jxns on chr22 (-).Loading annotations...\n",
      "done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find chr1 (-) in annotations...\n",
      "Could not find chr1 (+) in annotations...\n",
      "Could not find chr2 (-) in annotations...\n",
      "Could not find chr2 (+) in annotations...\n",
      "Could not find chr3 (-) in annotations...\n",
      "Could not find chr3 (+) in annotations...\n",
      "Could not find chr4 (+) in annotations...\n",
      "Could not find chr4 (-) in annotations...\n",
      "Could not find chr5 (+) in annotations...\n",
      "Could not find chr5 (-) in annotations...\n",
      "Could not find chr6 (+) in annotations...\n",
      "Could not find chr6 (-) in annotations...\n",
      "Could not find chr7 (-) in annotations...\n",
      "Could not find chr7 (+) in annotations...\n",
      "Could not find chr8 (-) in annotations...\n",
      "Could not find chr8 (+) in annotations...\n",
      "Could not find chr9 (-) in annotations...\n",
      "Could not find chr9 (+) in annotations...\n",
      "Could not find chr10 (+) in annotations...\n",
      "Could not find chr10 (-) in annotations...\n",
      "Could not find chr11 (-) in annotations...\n",
      "Could not find chr11 (+) in annotations...\n",
      "Could not find chr12 (-) in annotations...\n",
      "Could not find chr12 (+) in annotations...\n",
      "Could not find chr13 (-) in annotations...\n",
      "Could not find chr13 (+) in annotations...\n",
      "Could not find chr14 (+) in annotations...\n",
      "Could not find chr14 (-) in annotations...\n",
      "Could not find chr15 (-) in annotations...\n",
      "Could not find chr15 (+) in annotations...\n",
      "Could not find chr16 (-) in annotations...\n",
      "Could not find chr16 (+) in annotations...\n",
      "Could not find chr17 (-) in annotations...\n",
      "Could not find chr17 (+) in annotations...\n",
      "Could not find chr18 (+) in annotations...\n",
      "Could not find chr18 (-) in annotations...\n",
      "Could not find chr19 (-) in annotations...\n",
      "Could not find chr19 (+) in annotations...\n",
      "Could not find chr21 (+) in annotations...\n",
      "Could not find chr21 (-) in annotations...\n",
      "Could not find chr22 (+) in annotations...\n",
      "Could not find chr22 (-) in annotations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C20orf96 (chr20:-)\n",
      "LeafCutter junctions (36) All junctions (24) Start codons (3) Stop codons (1) \n",
      "Processing TBC1D20 (chr20:-)\n",
      "LeafCutter junctions (15) All junctions (27) Start codons (1) Stop codons (1) \n",
      "Processing CSNK2A1 (chr20:-)\n",
      "LeafCutter junctions (20) All junctions (47) Start codons (2) Stop codons (7) \n",
      "Processing SDCBP2 (chr20:-)\n",
      "LeafCutter junctions (4) All junctions (11) Start codons (2) Stop codons (1) \n",
      "Processing FKBP1A (chr20:-)\n",
      "LeafCutter junctions (14) All junctions (16) Start codons (1) Stop codons (4) \n",
      "Processing NSFL1C (chr20:-)\n",
      "LeafCutter junctions (25) All junctions (21) Start codons (1) Stop codons (1) \n",
      "Processing SIRPD (chr20:-)\n",
      "LeafCutter junctions (1) All junctions (6) Start codons (1) Stop codons (1) \n",
      "Processing AL049634.2 (chr20:-)\n",
      "LeafCutter junctions (21) All junctions (19) Start codons (2) Stop codons (2) \n",
      "Processing SIRPB1 (chr20:-)\n",
      "LeafCutter junctions (21) All junctions (29) Start codons (2) Stop codons (3) \n",
      "Processing SIRPG (chr20:-)\n",
      "LeafCutter junctions (10) All junctions (10) Start codons (2) Stop codons (1) \n",
      "Processing SNRPB (chr20:-)\n",
      "LeafCutter junctions (10) All junctions (9) Start codons (1) Stop codons (2) \n",
      "Processing ZNF343 (chr20:-)\n",
      "LeafCutter junctions (23) All junctions (18) Start codons (2) Stop codons (2) \n",
      "Processing IDH3B (chr20:-)\n",
      "LeafCutter junctions (15) All junctions (17) Start codons (1) Stop codons (4) \n",
      "Processing CPXM1 (chr20:-)\n",
      "LeafCutter junctions (20) All junctions (18) Start codons (1) Stop codons (1) \n",
      "Processing PCED1A (chr20:-)\n",
      "LeafCutter junctions (32) All junctions (21) Start codons (1) Stop codons (1) \n",
      "Processing UBOX5 (chr20:-)\n",
      "LeafCutter junctions (27) All junctions (18) Start codons (1) Stop codons (1) \n",
      "Processing FASTKD5 (chr20:-)\n",
      "LeafCutter junctions (15) All junctions (8) Start codons (1) Stop codons (1) \n",
      "Processing LZTS3 (chr20:-)\n",
      "LeafCutter junctions (6) All junctions (7) Start codons (1) Stop codons (1) \n",
      "Processing DDRGK1 (chr20:-)\n",
      "LeafCutter junctions (20) All junctions (16) Start codons (1) Stop codons (2) \n",
      "Processing SLC4A11 (chr20:-)\n",
      "LeafCutter junctions (5) All junctions (29) Start codons (4) Stop codons (1) \n",
      "Processing C20orf194 (chr20:-)\n",
      "LeafCutter junctions (35) All junctions (50) Start codons (1) Stop codons (1) \n",
      "Processing C20orf27 (chr20:-)\n",
      "LeafCutter junctions (10) All junctions (8) Start codons (1) Stop codons (1) \n",
      "Processing CENPB (chr20:-)\n",
      "LeafCutter junctions (2) All junctions (2) Start codons (1) Stop codons (1) \n",
      "Processing RNF24 (chr20:-)\n",
      "LeafCutter junctions (29) All junctions (19) Start codons (2) Stop codons (1) \n",
      "Processing RASSF2 (chr20:-)\n",
      "LeafCutter junctions (35) All junctions (27) Start codons (1) Stop codons (1) \n",
      "Processing SLC23A2 (chr20:-)\n",
      "LeafCutter junctions (37) All junctions (39) Start codons (1) Stop codons (1) \n",
      "Processing TMEM230 (chr20:-)\n",
      "LeafCutter junctions (8) All junctions (18) Start codons (2) Stop codons (2) \n",
      "Processing PCNA (chr20:-)\n",
      "LeafCutter junctions (2) All junctions (7) Start codons (1) Stop codons (1) \n",
      "Processing GPCPD1 (chr20:-)\n",
      "LeafCutter junctions (54) All junctions (43) Start codons (1) Stop codons (1) \n",
      "Processing TRMT6 (chr20:-)\n",
      "LeafCutter junctions (28) All junctions (17) Start codons (2) Stop codons (1) \n",
      "Processing FERMT1 (chr20:-)\n",
      "LeafCutter junctions (4) All junctions (19) Start codons (2) Stop codons (1) \n",
      "Processing TMX4 (chr20:-)\n",
      "LeafCutter junctions (8) All junctions (12) Start codons (1) Stop codons (1) \n",
      "Processing MKKS (chr20:-)\n",
      "LeafCutter junctions (18) All junctions (12) Start codons (1) Stop codons (1) \n",
      "Processing AL034430.1 (chr20:-)\n",
      "LeafCutter junctions (12) All junctions (7) Start codons (1) Stop codons (1) \n",
      "Processing JAG1 (chr20:-)\n",
      "LeafCutter junctions (19) All junctions (33) Start codons (1) Stop codons (2) \n",
      "Processing TASP1 (chr20:-)\n",
      "LeafCutter junctions (49) All junctions (40) Start codons (1) Stop codons (2) \n",
      "Processing ESF1 (chr20:-)\n",
      "LeafCutter junctions (23) All junctions (27) Start codons (1) Stop codons (1) \n",
      "Processing FLRT3 (chr20:-)\n",
      "LeafCutter junctions (8) All junctions (4) Start codons (1) Stop codons (1) \n",
      "Processing KIF16B (chr20:-)\n",
      "LeafCutter junctions (46) All junctions (44) Start codons (1) Stop codons (2) \n",
      "Processing RRBP1 (chr20:-)\n",
      "LeafCutter junctions (31) All junctions (41) Start codons (4) Stop codons (1) \n",
      "Processing SNX5 (chr20:-)\n",
      "LeafCutter junctions (25) All junctions (29) Start codons (1) Stop codons (4) \n",
      "Processing OVOL2 (chr20:-)\n",
      "LeafCutter junctions (12) All junctions (14) Start codons (1) Stop codons (1) \n",
      "Processing DZANK1 (chr20:-)\n",
      "LeafCutter junctions (75) All junctions (52) Start codons (4) Stop codons (1) \n",
      "Processing RBBP9 (chr20:-)\n",
      "LeafCutter junctions (12) All junctions (6) Start codons (1) Stop codons (1) \n",
      "Processing CRNKL1 (chr20:-)\n",
      "LeafCutter junctions (16) All junctions (24) Start codons (2) Stop codons (1) \n",
      "Processing RALGAPA2 (chr20:-)\n",
      "LeafCutter junctions (82) All junctions (72) Start codons (2) Stop codons (4) \n",
      "Processing NAPB (chr20:-)\n",
      "LeafCutter junctions (28) All junctions (22) Start codons (2) Stop codons (1) \n",
      "Processing APMAP (chr20:-)\n",
      "LeafCutter junctions (17) All junctions (13) Start codons (1) Stop codons (1) \n",
      "Processing ACSS1 (chr20:-)\n",
      "LeafCutter junctions (35) All junctions (26) Start codons (2) Stop codons (3) \n",
      "Processing ABHD12 (chr20:-)\n",
      "LeafCutter junctions (29) All junctions (44) Start codons (3) Stop codons (8) \n",
      "Processing NINL (chr20:-)\n",
      "LeafCutter junctions (14) All junctions (32) Start codons (1) Stop codons (1) \n",
      "Processing NANP (chr20:-)\n",
      "LeafCutter junctions (3) All junctions (3) Start codons (1) Stop codons (1) \n",
      "Processing ZNF337 (chr20:-)\n",
      "LeafCutter junctions (24) All junctions (16) Start codons (1) Stop codons (1) \n",
      "Processing BCL2L1 (chr20:-)\n",
      "LeafCutter junctions (39) All junctions (24) Start codons (1) Stop codons (1) \n",
      "Processing DUSP15 (chr20:-)\n",
      "LeafCutter junctions (14) All junctions (20) Start codons (3) Stop codons (2) \n",
      "Processing PDRG1 (chr20:-)\n",
      "LeafCutter junctions (4) All junctions (5) Start codons (1) Stop codons (1) \n",
      "Processing PLAGL2 (chr20:-)\n",
      "LeafCutter junctions (5) All junctions (5) Start codons (1) Stop codons (1) \n",
      "Processing NOL4L (chr20:-)\n",
      "LeafCutter junctions (57) All junctions (42) Start codons (3) Stop codons (6) \n",
      "Processing FO393400.1 (chr20:-)\n",
      "LeafCutter junctions (28) All junctions (28) Start codons (1) Stop codons (2) \n",
      "Processing COMMD7 (chr20:-)\n",
      "LeafCutter junctions (28) All junctions (19) Start codons (1) Stop codons (1) \n",
      "Processing CDK5RAP1 (chr20:-)\n",
      "LeafCutter junctions (33) All junctions (31) Start codons (2) Stop codons (1) \n",
      "Processing SNTA1 (chr20:-)\n",
      "LeafCutter junctions (10) All junctions (11) Start codons (1) Stop codons (1) \n",
      "Processing NECAB3 (chr20:-)\n",
      "LeafCutter junctions (29) All junctions (28) Start codons (2) Stop codons (2) \n",
      "Processing E2F1 (chr20:-)\n",
      "LeafCutter junctions (8) All junctions (8) Start codons (1) Stop codons (1) \n",
      "Processing PXMP4 (chr20:-)\n",
      "LeafCutter junctions (6) All junctions (5) Start codons (1) Stop codons (2) \n",
      "Processing EIF2S2 (chr20:-)\n",
      "LeafCutter junctions (6) All junctions (9) Start codons (1) Stop codons (1) \n",
      "Processing AHCY (chr20:-)\n",
      "LeafCutter junctions (23) All junctions (21) Start codons (2) Stop codons (1) \n",
      "Processing PIGU (chr20:-)\n",
      "LeafCutter junctions (21) All junctions (20) Start codons (1) Stop codons (1) \n",
      "Processing NCOA6 (chr20:-)\n",
      "LeafCutter junctions (42) All junctions (38) Start codons (1) Stop codons (2) \n",
      "Processing GGT7 (chr20:-)\n",
      "LeafCutter junctions (44) All junctions (33) Start codons (1) Stop codons (2) \n",
      "Processing GSS (chr20:-)\n",
      "LeafCutter junctions (30) All junctions (38) Start codons (1) Stop codons (3) \n",
      "Processing TRPC4AP (chr20:-)\n",
      "LeafCutter junctions (48) All junctions (38) Start codons (1) Stop codons (1) \n",
      "Processing EDEM2 (chr20:-)\n",
      "LeafCutter junctions (38) All junctions (22) Start codons (1) Stop codons (1) \n",
      "Processing MMP24OS (chr20:-)\n",
      "LeafCutter junctions (30) All junctions (24) Start codons (1) Stop codons (1) \n",
      "Processing EIF6 (chr20:-)\n",
      "LeafCutter junctions (10) All junctions (11) Start codons (1) Stop codons (1) \n",
      "Processing UQCC1 (chr20:-)\n",
      "LeafCutter junctions (29) All junctions (36) Start codons (2) Stop codons (2) \n",
      "Processing CPNE1 (chr20:-)\n",
      "LeafCutter junctions (34) All junctions (34) Start codons (2) Stop codons (2) \n",
      "Processing RBM12 (chr20:-)\n",
      "LeafCutter junctions (12) All junctions (10) Start codons (1) Stop codons (1) \n",
      "Processing NFS1 (chr20:-)\n",
      "LeafCutter junctions (6) All junctions (23) Start codons (2) Stop codons (2) \n",
      "Processing RBM39 (chr20:-)\n",
      "LeafCutter junctions (37) All junctions (48) Start codons (1) Stop codons (3) \n",
      "Processing Metazoa_SRP (chr20:-)\n",
      "Processing SLA2 (chr20:-)\n",
      "LeafCutter junctions (4) All junctions (8) Start codons (1) Stop codons (2) \n",
      "Processing NDRG3 (chr20:-)\n",
      "LeafCutter junctions (18) All junctions (22) Start codons (3) Stop codons (1) \n",
      "Processing DSN1 (chr20:-)\n",
      "LeafCutter junctions (27) All junctions (21) Start codons (3) Stop codons (1) \n",
      "Processing SOGA1 (chr20:-)\n",
      "LeafCutter junctions (16) All junctions (26) Start codons (2) Stop codons (2) \n",
      "Processing SAMHD1 (chr20:-)\n",
      "LeafCutter junctions (20) All junctions (31) Start codons (1) Stop codons (3) \n",
      "Processing RBL1 (chr20:-)\n",
      "LeafCutter junctions (29) All junctions (30) Start codons (1) Stop codons (2) \n",
      "Processing MROH8 (chr20:-)\n",
      "LeafCutter junctions (57) All junctions (43) Start codons (1) Stop codons (1) \n",
      "Processing BLCAP (chr20:-)\n",
      "LeafCutter junctions (21) All junctions (19) Start codons (1) Stop codons (1) \n",
      "Processing TTI1 (chr20:-)\n",
      "LeafCutter junctions (34) All junctions (19) Start codons (1) Stop codons (2) \n",
      "Processing SNORA71 (chr20:-)\n",
      "Processing ZHX3 (chr20:-)\n",
      "LeafCutter junctions (34) All junctions (39) Start codons (1) Stop codons (3) \n",
      "Processing CHD6 (chr20:-)\n",
      "LeafCutter junctions (84) All junctions (73) Start codons (2) Stop codons (3) \n",
      "Processing GTSF1L (chr20:-)\n",
      "LeafCutter junctions (2) All junctions (2) Start codons (1) Stop codons (1) \n",
      "Processing JPH2 (chr20:-)\n",
      "LeafCutter junctions (6) All junctions (7) Start codons (1) Stop codons (2) \n",
      "Processing OSER1 (chr20:-)\n",
      "LeafCutter junctions (24) All junctions (14) Start codons (1) Stop codons (1) \n",
      "Processing SERINC3 (chr20:-)\n",
      "LeafCutter junctions (11) All junctions (19) Start codons (1) Stop codons (1) \n",
      "Processing ADA (chr20:-)\n",
      "LeafCutter junctions (27) All junctions (22) Start codons (1) Stop codons (1) \n",
      "Processing TOMM34 (chr20:-)\n",
      "LeafCutter junctions (12) All junctions (9) Start codons (1) Stop codons (1) \n",
      "Processing SDC4 (chr20:-)\n",
      "LeafCutter junctions (6) All junctions (5) Start codons (1) Stop codons (1) \n",
      "Processing TP53TG5 (chr20:-)\n",
      "LeafCutter junctions (4) All junctions (8) Start codons (1) Stop codons (1) \n",
      "Processing WFDC3 (chr20:-)\n",
      "LeafCutter junctions (4) All junctions (18) Start codons (1) Stop codons (1) \n",
      "Processing ACOT8 (chr20:-)\n",
      "LeafCutter junctions (23) All junctions (14) Start codons (2) Stop codons (3) \n",
      "Processing SPATA25 (chr20:-)\n",
      "LeafCutter junctions (4) All junctions (2) Start codons (1) Stop codons (1) \n",
      "Processing NEURL2 (chr20:-)\n",
      "LeafCutter junctions (4) All junctions (2) Start codons (1) Stop codons (2) \n",
      "Processing PLTP (chr20:-)\n",
      "LeafCutter junctions (20) All junctions (21) Start codons (2) Stop codons (1) \n",
      "Processing ZNF335 (chr20:-)\n",
      "LeafCutter junctions (50) All junctions (46) Start codons (1) Stop codons (1) \n",
      "Processing NCOA5 (chr20:-)\n",
      "LeafCutter junctions (11) All junctions (10) Start codons (2) Stop codons (1) \n",
      "Processing SLC35C2 (chr20:-)\n",
      "LeafCutter junctions (29) All junctions (22) Start codons (2) Stop codons (1) \n",
      "Processing ELMO2 (chr20:-)\n",
      "LeafCutter junctions (49) All junctions (39) Start codons (2) Stop codons (2) \n",
      "Processing ZNF334 (chr20:-)\n",
      "LeafCutter junctions (42) All junctions (25) Start codons (4) Stop codons (1) \n",
      "Processing OCSTAMP (chr20:-)\n",
      "LeafCutter junctions (11) All junctions (6) Start codons (1) Stop codons (1) \n",
      "Processing SLC13A3 (chr20:-)\n",
      "LeafCutter junctions (7) All junctions (24) Start codons (2) Stop codons (3) \n",
      "Processing TP53RK (chr20:-)\n",
      "LeafCutter junctions (5) All junctions (3) Start codons (1) Stop codons (2) \n",
      "Processing ZMYND8 (chr20:-)\n",
      "LeafCutter junctions (33) All junctions (42) Start codons (4) Stop codons (2) \n",
      "Processing SULF2 (chr20:-)\n",
      "LeafCutter junctions (55) All junctions (43) Start codons (1) Stop codons (1) \n",
      "Processing PREX1 (chr20:-)\n",
      "LeafCutter junctions (23) All junctions (49) Start codons (1) Stop codons (2) \n",
      "Processing STAU1 (chr20:-)\n",
      "LeafCutter junctions (24) All junctions (23) Start codons (3) Stop codons (1) \n",
      "Processing ZNFX1 (chr20:-)\n",
      "LeafCutter junctions (20) All junctions (25) Start codons (1) Stop codons (2) \n",
      "Processing B4GALT5 (chr20:-)\n",
      "LeafCutter junctions (18) All junctions (17) Start codons (1) Stop codons (1) \n",
      "Processing SPATA2 (chr20:-)\n",
      "LeafCutter junctions (14) All junctions (10) Start codons (1) Stop codons (1) \n",
      "Processing UBE2V1 (chr20:-)\n",
      "LeafCutter junctions (22) All junctions (25) Start codons (5) Stop codons (1) \n",
      "Processing PEDS1-UBE2V1 (chr20:-)\n",
      "LeafCutter junctions (28) All junctions (18) Start codons (1) Stop codons (1) \n",
      "Processing PEDS1 (chr20:-)\n",
      "LeafCutter junctions (6) All junctions (10) Start codons (2) Stop codons (1) \n",
      "Processing ADNP (chr20:-)\n",
      "LeafCutter junctions (24) All junctions (19) Start codons (3) Stop codons (2) \n",
      "Processing DPM1 (chr20:-)\n",
      "LeafCutter junctions (20) All junctions (16) Start codons (1) Stop codons (1) \n",
      "Processing NFATC2 (chr20:-)\n",
      "LeafCutter junctions (43) All junctions (30) Start codons (3) Stop codons (2) \n",
      "Processing ZFP64 (chr20:-)\n",
      "LeafCutter junctions (24) All junctions (25) Start codons (3) Stop codons (5) \n",
      "Processing ZNF217 (chr20:-)\n",
      "LeafCutter junctions (24) All junctions (17) Start codons (1) Stop codons (2) \n",
      "Processing BCAS1 (chr20:-)\n",
      "LeafCutter junctions (48) All junctions (31) Start codons (1) Stop codons (2) \n",
      "Processing AURKA (chr20:-)\n",
      "LeafCutter junctions (36) All junctions (24) Start codons (1) Stop codons (2) \n",
      "Processing ZBP1 (chr20:-)\n",
      "LeafCutter junctions (44) All junctions (25) Start codons (1) Stop codons (2) \n",
      "Processing PMEPA1 (chr20:-)\n",
      "LeafCutter junctions (6) All junctions (10) Start codons (4) Stop codons (1) \n",
      "Processing CTSZ (chr20:-)\n",
      "LeafCutter junctions (4) All junctions (32) Start codons (2) Stop codons (10) \n",
      "Processing PRELID3B (chr20:-)\n",
      "LeafCutter junctions (12) All junctions (8) Start codons (1) Stop codons (1) \n",
      "Processing SYCP2 (chr20:-)\n",
      "LeafCutter junctions (58) All junctions (70) Start codons (1) Stop codons (1) \n",
      "Processing TAF4 (chr20:-)\n",
      "LeafCutter junctions (39) All junctions (40) Start codons (1) Stop codons (2) \n",
      "Processing PSMA7 (chr20:-)\n",
      "LeafCutter junctions (8) All junctions (9) Start codons (2) Stop codons (2) \n",
      "Processing LAMA5 (chr20:-)\n",
      "LeafCutter junctions (16) All junctions (95) Start codons (1) Stop codons (1) \n",
      "Processing CABLES2 (chr20:-)\n",
      "LeafCutter junctions (8) All junctions (13) Start codons (1) Stop codons (1) \n",
      "Processing TCFL5 (chr20:-)\n",
      "LeafCutter junctions (44) All junctions (23) Start codons (2) Stop codons (2) \n",
      "Processing DIDO1 (chr20:-)\n",
      "LeafCutter junctions (38) All junctions (27) Start codons (1) Stop codons (4) \n",
      "Processing YTHDF1 (chr20:-)\n",
      "LeafCutter junctions (12) All junctions (8) Start codons (1) Stop codons (1) \n",
      "Processing KCNQ2 (chr20:-)\n",
      "LeafCutter junctions (13) All junctions (60) Start codons (2) Stop codons (7) \n",
      "Processing EEF1A2 (chr20:-)\n",
      "LeafCutter junctions (6) All junctions (12) Start codons (1) Stop codons (1) \n",
      "Processing PTK6 (chr20:-)\n",
      "LeafCutter junctions (6) All junctions (11) Start codons (1) Stop codons (2) \n",
      "Processing HELZ2 (chr20:-)\n",
      "LeafCutter junctions (37) All junctions (44) Start codons (2) Stop codons (1) \n",
      "Processing GMEB2 (chr20:-)\n",
      "LeafCutter junctions (32) All junctions (23) Start codons (2) Stop codons (1) \n",
      "Processing STMN3 (chr20:-)\n",
      "LeafCutter junctions (5) All junctions (10) Start codons (2) Stop codons (1) \n",
      "Processing ARFRP1 (chr20:-)\n",
      "LeafCutter junctions (33) All junctions (19) Start codons (2) Stop codons (3) \n",
      "Processing ZBTB46 (chr20:-)\n",
      "LeafCutter junctions (7) All junctions (14) Start codons (1) Stop codons (1) \n",
      "Processing UCKL1 (chr20:-)\n",
      "LeafCutter junctions (58) All junctions (41) Start codons (3) Stop codons (2) \n",
      "Processing ZNF512B (chr20:-)\n",
      "LeafCutter junctions (81) All junctions (61) Start codons (1) Stop codons (1) \n",
      "Processing SAMD10 (chr20:-)\n",
      "LeafCutter junctions (33) All junctions (21) Start codons (1) Stop codons (1) \n",
      "Processing RGS19 (chr20:-)\n",
      "LeafCutter junctions (26) All junctions (15) Start codons (1) Stop codons (1) \n",
      "Processing NRSN2 (chr20:+)\n",
      "LeafCutter junctions (37) All junctions (21) Start codons (1) Stop codons (4) \n",
      "Processing TRIB3 (chr20:+)\n",
      "LeafCutter junctions (8) All junctions (11) Start codons (2) Stop codons (1) \n",
      "Processing RBCK1 (chr20:+)\n",
      "LeafCutter junctions (40) All junctions (31) Start codons (3) Stop codons (2) \n",
      "Processing FAM110A (chr20:+)\n",
      "LeafCutter junctions (11) All junctions (8) Start codons (1) Stop codons (1) \n",
      "Processing PSMF1 (chr20:+)\n",
      "LeafCutter junctions (16) All junctions (20) Start codons (1) Stop codons (3) \n",
      "Processing C20orf202 (chr20:+)\n",
      "LeafCutter junctions (2) All junctions (2) Start codons (1) Stop codons (1) \n",
      "Processing SIRPA (chr20:+)\n",
      "LeafCutter junctions (21) All junctions (15) Start codons (1) Stop codons (1) \n",
      "Processing STK35 (chr20:+)\n",
      "LeafCutter junctions (14) All junctions (10) Start codons (1) Stop codons (1) \n",
      "Processing AL121899.2 (chr20:+)\n",
      "LeafCutter junctions (4) All junctions (15) Start codons (1) Stop codons (1) \n",
      "Processing NOP56 (chr20:+)\n",
      "LeafCutter junctions (20) All junctions (21) Start codons (1) Stop codons (2) \n",
      "Processing EBF4 (chr20:+)\n",
      "LeafCutter junctions (3) All junctions (22) Start codons (3) Stop codons (2) \n",
      "Processing VPS16 (chr20:+)\n",
      "LeafCutter junctions (46) All junctions (40) Start codons (2) Stop codons (1) \n",
      "Processing PTPRA (chr20:+)\n",
      "LeafCutter junctions (50) All junctions (51) Start codons (1) Stop codons (1) \n",
      "Processing GNRH2 (chr20:+)\n",
      "LeafCutter junctions (2) All junctions (5) Start codons (1) Stop codons (1) \n",
      "Processing MRPS26 (chr20:+)\n",
      "LeafCutter junctions (6) All junctions (5) Start codons (1) Stop codons (1) \n",
      "Processing ITPA (chr20:+)\n",
      "LeafCutter junctions (22) All junctions (17) Start codons (1) Stop codons (1) \n",
      "Processing ATRN (chr20:+)\n",
      "LeafCutter junctions (51) All junctions (46) Start codons (1) Stop codons (2) \n",
      "Processing CDC25B (chr20:+)\n",
      "LeafCutter junctions (34) All junctions (31) Start codons (2) Stop codons (1) \n",
      "Processing AP5S1 (chr20:+)\n",
      "LeafCutter junctions (11) All junctions (8) Start codons (1) Stop codons (2) \n",
      "Processing MAVS (chr20:+)\n",
      "LeafCutter junctions (13) All junctions (10) Start codons (2) Stop codons (1) \n",
      "Processing PANK2 (chr20:+)\n",
      "LeafCutter junctions (24) All junctions (18) Start codons (4) Stop codons (1) \n",
      "Processing SMOX (chr20:+)\n",
      "LeafCutter junctions (5) All junctions (17) Start codons (1) Stop codons (1) \n",
      "Processing PRNP (chr20:+)\n",
      "LeafCutter junctions (8) All junctions (4) Start codons (1) Stop codons (1) \n",
      "Processing CDS2 (chr20:+)\n",
      "LeafCutter junctions (18) All junctions (19) Start codons (2) Stop codons (1) \n",
      "Processing SHLD1 (chr20:+)\n",
      "LeafCutter junctions (30) All junctions (19) Start codons (2) Stop codons (2) \n",
      "Processing MCM8 (chr20:+)\n",
      "LeafCutter junctions (67) All junctions (41) Start codons (1) Stop codons (1) \n",
      "Processing AL035461.3 (chr20:+)\n",
      "LeafCutter junctions (97) All junctions (57) Start codons (1) Stop codons (1) \n",
      "Processing CRLS1 (chr20:+)\n",
      "LeafCutter junctions (31) All junctions (21) Start codons (2) Stop codons (2) \n",
      "Processing BMP2 (chr20:+)\n",
      "LeafCutter junctions (6) All junctions (3) Start codons (1) Stop codons (1) \n",
      "Processing PLCB1 (chr20:+)\n",
      "LeafCutter junctions (2) All junctions (64) Start codons (2) Stop codons (9) \n",
      "Processing LAMP5 (chr20:+)\n",
      "LeafCutter junctions (22) All junctions (12) Start codons (1) Stop codons (1) \n",
      "Processing ANKEF1 (chr20:+)\n",
      "LeafCutter junctions (8) All junctions (14) Start codons (1) Stop codons (1) \n",
      "Processing SLX4IP (chr20:+)\n",
      "LeafCutter junctions (64) All junctions (44) Start codons (1) Stop codons (1) \n",
      "Processing BTBD3 (chr20:+)\n",
      "LeafCutter junctions (14) All junctions (15) Start codons (3) Stop codons (1) \n",
      "Processing NDUFAF5 (chr20:+)\n",
      "LeafCutter junctions (48) All junctions (28) Start codons (1) Stop codons (1) \n",
      "Processing MACROD2 (chr20:+)\n",
      "LeafCutter junctions (29) All junctions (41) Start codons (3) Stop codons (1) \n",
      "Processing SNRPB2 (chr20:+)\n",
      "LeafCutter junctions (12) All junctions (9) Start codons (1) Stop codons (1) \n",
      "Processing DSTN (chr20:+)\n",
      "LeafCutter junctions (6) All junctions (7) Start codons (2) Stop codons (1) \n",
      "Processing MGME1 (chr20:+)\n",
      "LeafCutter junctions (26) All junctions (14) Start codons (1) Stop codons (2) \n",
      "Processing KAT14 (chr20:+)\n",
      "LeafCutter junctions (18) All junctions (22) Start codons (2) Stop codons (1) \n",
      "Processing PET117 (chr20:+)\n",
      "LeafCutter junctions (10) All junctions (5) Start codons (1) Stop codons (1) \n",
      "Processing ZNF133 (chr20:+)\n",
      "LeafCutter junctions (75) All junctions (40) Start codons (5) Stop codons (1) \n",
      "Processing POLR3F (chr20:+)\n",
      "LeafCutter junctions (27) All junctions (17) Start codons (1) Stop codons (1) \n",
      "Processing SEC23B (chr20:+)\n",
      "LeafCutter junctions (12) All junctions (29) Start codons (1) Stop codons (1) \n",
      "Processing SMIM26 (chr20:+)\n",
      "LeafCutter junctions (4) All junctions (3) Start codons (1) Stop codons (2) \n",
      "Processing DTD1 (chr20:+)\n",
      "LeafCutter junctions (6) All junctions (11) Start codons (1) Stop codons (2) \n",
      "Processing RIN2 (chr20:+)\n",
      "LeafCutter junctions (3) All junctions (27) Start codons (1) Stop codons (1) \n",
      "Processing NAA20 (chr20:+)\n",
      "LeafCutter junctions (6) All junctions (12) Start codons (2) Stop codons (2) \n",
      "Processing KIZ (chr20:+)\n",
      "LeafCutter junctions (50) All junctions (42) Start codons (3) Stop codons (2) \n",
      "Processing XRN2 (chr20:+)\n",
      "LeafCutter junctions (9) All junctions (34) Start codons (1) Stop codons (1) \n",
      "Processing NXT1 (chr20:+)\n",
      "LeafCutter junctions (4) All junctions (2) Start codons (1) Stop codons (1) \n",
      "Processing GZF1 (chr20:+)\n",
      "LeafCutter junctions (26) All junctions (15) Start codons (1) Stop codons (1) \n",
      "Processing ENTPD6 (chr20:+)\n",
      "LeafCutter junctions (65) All junctions (39) Start codons (2) Stop codons (2) \n",
      "Processing PYGB (chr20:+)\n",
      "LeafCutter junctions (41) All junctions (34) Start codons (1) Stop codons (1) \n",
      "Processing GINS1 (chr20:+)\n",
      "LeafCutter junctions (34) All junctions (19) Start codons (1) Stop codons (1) \n",
      "Processing HM13 (chr20:+)\n",
      "LeafCutter junctions (32) All junctions (38) Start codons (1) Stop codons (4) \n",
      "Processing MCTS2P (chr20:+)\n",
      "LeafCutter junctions (6) All junctions (4) Start codons (1) Stop codons (1) \n",
      "Processing COX4I2 (chr20:+)\n",
      "LeafCutter junctions (9) All junctions (6) Start codons (1) Stop codons (1) \n",
      "Processing TPX2 (chr20:+)\n",
      "LeafCutter junctions (20) All junctions (25) Start codons (1) Stop codons (1) \n",
      "Processing MYLK2 (chr20:+)\n",
      "LeafCutter junctions (6) All junctions (15) Start codons (1) Stop codons (1) \n",
      "Processing TTLL9 (chr20:+)\n",
      "LeafCutter junctions (15) All junctions (40) Start codons (3) Stop codons (2) \n",
      "Processing HCK (chr20:+)\n",
      "LeafCutter junctions (26) All junctions (22) Start codons (2) Stop codons (1) \n",
      "Processing TM9SF4 (chr20:+)\n",
      "LeafCutter junctions (38) All junctions (31) Start codons (2) Stop codons (1) \n",
      "Processing POFUT1 (chr20:+)\n",
      "LeafCutter junctions (21) All junctions (17) Start codons (1) Stop codons (2) \n",
      "Processing KIF3B (chr20:+)\n",
      "LeafCutter junctions (19) All junctions (16) Start codons (1) Stop codons (1) \n",
      "Processing ASXL1 (chr20:+)\n",
      "LeafCutter junctions (55) All junctions (39) Start codons (4) Stop codons (3) \n",
      "Processing DNMT3B (chr20:+)\n",
      "LeafCutter junctions (18) All junctions (30) Start codons (2) Stop codons (1) \n",
      "Processing MAPRE1 (chr20:+)\n",
      "LeafCutter junctions (4) All junctions (7) Start codons (1) Stop codons (1) \n",
      "Processing EFCAB8 (chr20:+)\n",
      "LeafCutter junctions (9) All junctions (31) Start codons (1) Stop codons (2) \n",
      "Processing CBFA2T2 (chr20:+)\n",
      "LeafCutter junctions (57) All junctions (42) Start codons (5) Stop codons (2) \n",
      "Processing ZNF341 (chr20:+)\n",
      "LeafCutter junctions (15) All junctions (20) Start codons (1) Stop codons (1) \n",
      "Processing RALY (chr20:+)\n",
      "LeafCutter junctions (16) All junctions (19) Start codons (1) Stop codons (1) \n",
      "Processing ITCH (chr20:+)\n",
      "LeafCutter junctions (63) All junctions (58) Start codons (2) Stop codons (1) \n",
      "Processing DYNLRB1 (chr20:+)\n",
      "LeafCutter junctions (15) All junctions (10) Start codons (2) Stop codons (2) \n",
      "Processing TP53INP2 (chr20:+)\n",
      "LeafCutter junctions (8) All junctions (8) Start codons (1) Stop codons (1) \n",
      "Processing ACSS2 (chr20:+)\n",
      "LeafCutter junctions (29) All junctions (42) Start codons (2) Stop codons (1) \n",
      "Processing PROCR (chr20:+)\n",
      "LeafCutter junctions (4) All junctions (6) Start codons (1) Stop codons (2) \n",
      "Processing CEP250 (chr20:+)\n",
      "LeafCutter junctions (94) All junctions (64) Start codons (1) Stop codons (3) \n",
      "Processing ERGIC3 (chr20:+)\n",
      "LeafCutter junctions (22) All junctions (29) Start codons (1) Stop codons (3) \n",
      "Processing SPAG4 (chr20:+)\n",
      "LeafCutter junctions (38) All junctions (26) Start codons (3) Stop codons (1) \n",
      "Processing ROMO1 (chr20:+)\n",
      "LeafCutter junctions (10) All junctions (5) Start codons (1) Stop codons (2) \n",
      "Processing PHF20 (chr20:+)\n",
      "LeafCutter junctions (42) All junctions (43) Start codons (3) Stop codons (1) \n",
      "Processing CNBD2 (chr20:+)\n",
      "LeafCutter junctions (10) All junctions (19) Start codons (2) Stop codons (4) \n",
      "Processing EPB41L1 (chr20:+)\n",
      "LeafCutter junctions (10) All junctions (53) Start codons (3) Stop codons (1) \n",
      "Processing AAR2 (chr20:+)\n",
      "LeafCutter junctions (18) All junctions (15) Start codons (1) Stop codons (2) \n",
      "Processing DLGAP4 (chr20:+)\n",
      "LeafCutter junctions (27) All junctions (30) Start codons (4) Stop codons (2) \n",
      "Processing MYL9 (chr20:+)\n",
      "LeafCutter junctions (8) All junctions (5) Start codons (1) Stop codons (1) \n",
      "Processing TGIF2 (chr20:+)\n",
      "LeafCutter junctions (14) All junctions (12) Start codons (1) Stop codons (3) \n",
      "Processing TGIF2-RAB5IF (chr20:+)\n",
      "LeafCutter junctions (36) All junctions (19) Start codons (1) Stop codons (1) \n",
      "Processing RAB5IF (chr20:+)\n",
      "LeafCutter junctions (24) All junctions (18) Start codons (1) Stop codons (3) \n",
      "Processing TLDC2 (chr20:+)\n",
      "LeafCutter junctions (6) All junctions (8) Start codons (1) Stop codons (2) \n",
      "Processing RPN2 (chr20:+)\n",
      "LeafCutter junctions (15) All junctions (26) Start codons (2) Stop codons (2) \n",
      "Processing MANBAL (chr20:+)\n",
      "LeafCutter junctions (19) All junctions (15) Start codons (1) Stop codons (2) \n",
      "Processing SRC (chr20:+)\n",
      "LeafCutter junctions (37) All junctions (39) Start codons (1) Stop codons (1) \n",
      "Processing NNAT (chr20:+)\n",
      "LeafCutter junctions (6) All junctions (6) Start codons (1) Stop codons (3) \n",
      "Processing CTNNBL1 (chr20:+)\n",
      "LeafCutter junctions (16) All junctions (33) Start codons (4) Stop codons (1) \n",
      "Processing VSTM2L (chr20:+)\n",
      "LeafCutter junctions (6) All junctions (5) Start codons (1) Stop codons (2) \n",
      "Processing RPRD1B (chr20:+)\n",
      "LeafCutter junctions (30) All junctions (24) Start codons (2) Stop codons (3) \n",
      "Processing RALGAPB (chr20:+)\n",
      "LeafCutter junctions (41) All junctions (47) Start codons (1) Stop codons (1) \n",
      "Processing ARHGAP40 (chr20:+)\n",
      "LeafCutter junctions (3) All junctions (17) Start codons (1) Stop codons (3) \n",
      "Processing ACTR5 (chr20:+)\n",
      "LeafCutter junctions (24) All junctions (16) Start codons (1) Stop codons (1) \n",
      "Processing PPP1R16B (chr20:+)\n",
      "LeafCutter junctions (12) All junctions (17) Start codons (1) Stop codons (1) \n",
      "Processing FAM83D (chr20:+)\n",
      "LeafCutter junctions (6) All junctions (5) Start codons (2) Stop codons (1) \n",
      "Processing DHX35 (chr20:+)\n",
      "LeafCutter junctions (45) All junctions (36) Start codons (1) Stop codons (1) \n",
      "Processing TOP1 (chr20:+)\n",
      "LeafCutter junctions (8) All junctions (27) Start codons (2) Stop codons (1) \n",
      "Processing PLCG1 (chr20:+)\n",
      "LeafCutter junctions (59) All junctions (67) Start codons (1) Stop codons (2) \n",
      "Processing LPIN3 (chr20:+)\n",
      "LeafCutter junctions (34) All junctions (36) Start codons (1) Stop codons (1) \n",
      "Processing SRSF6 (chr20:+)\n",
      "LeafCutter junctions (14) All junctions (12) Start codons (1) Stop codons (3) \n",
      "Processing AL031681.2 (chr20:+)\n",
      "LeafCutter junctions (72) All junctions (52) Start codons (0) Stop codons (1) \n",
      "Processing L3MBTL1 (chr20:+)\n",
      "LeafCutter junctions (58) All junctions (54) Start codons (5) Stop codons (3) \n",
      "Processing IFT52 (chr20:+)\n",
      "LeafCutter junctions (21) All junctions (23) Start codons (1) Stop codons (1) \n",
      "Processing MYBL2 (chr20:+)\n",
      "LeafCutter junctions (10) All junctions (15) Start codons (1) Stop codons (1) \n",
      "Processing TOX2 (chr20:+)\n",
      "LeafCutter junctions (29) All junctions (22) Start codons (3) Stop codons (2) \n",
      "Processing TTPAL (chr20:+)\n",
      "LeafCutter junctions (44) All junctions (23) Start codons (1) Stop codons (2) \n",
      "Processing PKIG (chr20:+)\n",
      "LeafCutter junctions (20) All junctions (12) Start codons (1) Stop codons (2) \n",
      "Processing YWHAB (chr20:+)\n",
      "LeafCutter junctions (10) All junctions (13) Start codons (1) Stop codons (1) \n",
      "Processing PABPC1L (chr20:+)\n",
      "LeafCutter junctions (82) All junctions (53) Start codons (1) Stop codons (4) \n",
      "Processing STK4 (chr20:+)\n",
      "LeafCutter junctions (26) All junctions (29) Start codons (2) Stop codons (2) \n",
      "Processing SYS1 (chr20:+)\n",
      "LeafCutter junctions (11) All junctions (12) Start codons (2) Stop codons (3) \n",
      "Processing DBNDD2 (chr20:+)\n",
      "LeafCutter junctions (11) All junctions (10) Start codons (2) Stop codons (2) \n",
      "Processing PIGT (chr20:+)\n",
      "LeafCutter junctions (53) All junctions (59) Start codons (1) Stop codons (5) \n",
      "Processing WFDC2 (chr20:+)\n",
      "LeafCutter junctions (16) All junctions (12) Start codons (2) Stop codons (2) \n",
      "Processing DNTTIP1 (chr20:+)\n",
      "LeafCutter junctions (17) All junctions (19) Start codons (2) Stop codons (2) \n",
      "Processing UBE2C (chr20:+)\n",
      "LeafCutter junctions (18) All junctions (13) Start codons (2) Stop codons (2) \n",
      "Processing SNX21 (chr20:+)\n",
      "LeafCutter junctions (9) All junctions (13) Start codons (2) Stop codons (4) \n",
      "Processing ZSWIM3 (chr20:+)\n",
      "LeafCutter junctions (12) All junctions (7) Start codons (1) Stop codons (1) \n",
      "Processing ZSWIM1 (chr20:+)\n",
      "LeafCutter junctions (12) All junctions (6) Start codons (1) Stop codons (1) \n",
      "Processing CTSA (chr20:+)\n",
      "LeafCutter junctions (22) All junctions (34) Start codons (2) Stop codons (2) \n",
      "Processing PCIF1 (chr20:+)\n",
      "LeafCutter junctions (36) All junctions (27) Start codons (1) Stop codons (2) \n",
      "Processing SLC12A5 (chr20:+)\n",
      "LeafCutter junctions (8) All junctions (46) Start codons (3) Stop codons (8) \n",
      "Processing CD40 (chr20:+)\n",
      "LeafCutter junctions (31) All junctions (21) Start codons (1) Stop codons (3) \n",
      "Processing EYA2 (chr20:+)\n",
      "LeafCutter junctions (9) All junctions (23) Start codons (1) Stop codons (1) \n",
      "Processing NCOA3 (chr20:+)\n",
      "LeafCutter junctions (57) All junctions (47) Start codons (1) Stop codons (1) \n",
      "Processing ARFGEF2 (chr20:+)\n",
      "LeafCutter junctions (49) All junctions (56) Start codons (1) Stop codons (2) \n",
      "Processing CSE1L (chr20:+)\n",
      "LeafCutter junctions (4) All junctions (26) Start codons (1) Stop codons (1) \n",
      "Processing DDX27 (chr20:+)\n",
      "LeafCutter junctions (11) All junctions (25) Start codons (1) Stop codons (1) \n",
      "Processing SLC9A8 (chr20:+)\n",
      "LeafCutter junctions (42) All junctions (29) Start codons (1) Stop codons (1) \n",
      "Processing RNF114 (chr20:+)\n",
      "LeafCutter junctions (14) All junctions (15) Start codons (1) Stop codons (2) \n",
      "Processing PTPN1 (chr20:+)\n",
      "LeafCutter junctions (10) All junctions (12) Start codons (2) Stop codons (1) \n",
      "Processing PARD6B (chr20:+)\n",
      "LeafCutter junctions (4) All junctions (5) Start codons (1) Stop codons (2) \n",
      "Processing BCAS4 (chr20:+)\n",
      "LeafCutter junctions (28) All junctions (16) Start codons (2) Stop codons (2) \n",
      "Processing PFDN4 (chr20:+)\n",
      "LeafCutter junctions (7) All junctions (11) Start codons (1) Stop codons (1) \n",
      "Processing FAM210B (chr20:+)\n",
      "LeafCutter junctions (4) All junctions (3) Start codons (1) Stop codons (2) \n",
      "Processing CSTF1 (chr20:+)\n",
      "LeafCutter junctions (18) All junctions (13) Start codons (1) Stop codons (1) \n",
      "Processing CASS4 (chr20:+)\n",
      "LeafCutter junctions (3) All junctions (8) Start codons (1) Stop codons (1) \n",
      "Processing RTF2 (chr20:+)\n",
      "LeafCutter junctions (16) All junctions (16) Start codons (1) Stop codons (2) \n",
      "Processing FAM209B (chr20:+)\n",
      "LeafCutter junctions (1) All junctions (2) Start codons (1) Stop codons (1) \n",
      "Processing RAE1 (chr20:+)\n",
      "LeafCutter junctions (14) All junctions (20) Start codons (1) Stop codons (2) \n",
      "Processing RBM38 (chr20:+)\n",
      "LeafCutter junctions (22) All junctions (11) Start codons (3) Stop codons (2) \n",
      "Processing RAB22A (chr20:+)\n",
      "LeafCutter junctions (19) All junctions (13) Start codons (1) Stop codons (1) \n",
      "Processing VAPB (chr20:+)\n",
      "LeafCutter junctions (22) All junctions (15) Start codons (1) Stop codons (2) \n",
      "Processing STX16 (chr20:+)\n",
      "LeafCutter junctions (36) All junctions (28) Start codons (2) Stop codons (1) \n",
      "Processing NPEPL1 (chr20:+)\n",
      "LeafCutter junctions (49) All junctions (38) Start codons (3) Stop codons (1) \n",
      "Processing GNAS (chr20:+)\n",
      "LeafCutter junctions (24) All junctions (44) Start codons (9) Stop codons (6) \n",
      "Processing NELFCD (chr20:+)\n",
      "LeafCutter junctions (23) All junctions (24) Start codons (2) Stop codons (1) \n",
      "Processing ZNF831 (chr20:+)\n",
      "LeafCutter junctions (8) All junctions (14) Start codons (1) Stop codons (1) \n",
      "Processing FAM217B (chr20:+)\n",
      "LeafCutter junctions (22) All junctions (13) Start codons (1) Stop codons (1) \n",
      "Processing CDH26 (chr20:+)\n",
      "LeafCutter junctions (10) All junctions (25) Start codons (2) Stop codons (2) \n",
      "Processing LSM14B (chr20:+)\n",
      "LeafCutter junctions (36) All junctions (23) Start codons (2) Stop codons (2) \n",
      "Processing SS18L1 (chr20:+)\n",
      "LeafCutter junctions (43) All junctions (33) Start codons (3) Stop codons (1) \n",
      "Processing MTG2 (chr20:+)\n",
      "LeafCutter junctions (31) All junctions (22) Start codons (1) Stop codons (1) \n",
      "Processing OSBPL2 (chr20:+)\n",
      "LeafCutter junctions (58) All junctions (48) Start codons (4) Stop codons (5) \n",
      "Processing ADRM1 (chr20:+)\n",
      "LeafCutter junctions (18) All junctions (14) Start codons (1) Stop codons (1) \n",
      "Processing RPS21 (chr20:+)\n",
      "LeafCutter junctions (6) All junctions (6) Start codons (1) Stop codons (4) \n",
      "Processing SLCO4A1 (chr20:+)\n",
      "LeafCutter junctions (44) All junctions (29) Start codons (1) Stop codons (1) \n",
      "Processing MRGBP (chr20:+)\n",
      "LeafCutter junctions (20) All junctions (10) Start codons (1) Stop codons (1) \n",
      "Processing OGFR (chr20:+)\n",
      "LeafCutter junctions (8) All junctions (9) Start codons (3) Stop codons (1) \n",
      "Processing COL9A3 (chr20:+)\n",
      "LeafCutter junctions (17) All junctions (43) Start codons (2) Stop codons (1) \n",
      "Processing GID8 (chr20:+)\n",
      "LeafCutter junctions (7) All junctions (8) Start codons (1) Stop codons (1) \n",
      "Processing SLC17A9 (chr20:+)\n",
      "LeafCutter junctions (44) All junctions (27) Start codons (3) Stop codons (1) \n",
      "Processing BIRC7 (chr20:+)\n",
      "LeafCutter junctions (10) All junctions (10) Start codons (2) Stop codons (1) \n",
      "Processing ARFGAP1 (chr20:+)\n",
      "LeafCutter junctions (37) All junctions (35) Start codons (4) Stop codons (3) \n",
      "Processing PPDPF (chr20:+)\n",
      "LeafCutter junctions (14) All junctions (7) Start codons (1) Stop codons (1) \n",
      "Processing FNDC11 (chr20:+)\n",
      "LeafCutter junctions (3) All junctions (5) Start codons (1) Stop codons (1) \n",
      "Processing RTEL1 (chr20:+)\n",
      "LeafCutter junctions (100) All junctions (77) Start codons (2) Stop codons (2) \n",
      "Processing ZGPAT (chr20:+)\n",
      "LeafCutter junctions (25) All junctions (18) Start codons (1) Stop codons (1) \n",
      "Processing AL121845.3 (chr20:+)\n",
      "LeafCutter junctions (35) All junctions (25) Start codons (0) Stop codons (1) \n",
      "Processing LIME1 (chr20:+)\n",
      "LeafCutter junctions (19) All junctions (14) Start codons (1) Stop codons (2) \n",
      "Processing SLC2A4RG (chr20:+)\n",
      "LeafCutter junctions (15) All junctions (13) Start codons (1) Stop codons (1) \n",
      "Processing TPD52L2 (chr20:+)\n",
      "LeafCutter junctions (20) All junctions (18) Start codons (1) Stop codons (2) \n",
      "Processing DNAJC5 (chr20:+)\n",
      "LeafCutter junctions (14) All junctions (8) Start codons (1) Stop codons (1) \n",
      "Processing PRPF6 (chr20:+)\n",
      "LeafCutter junctions (9) All junctions (26) Start codons (1) Stop codons (1) \n",
      "Processing C20orf204 (chr20:+)\n",
      "LeafCutter junctions (7) All junctions (6) Start codons (1) Stop codons (1) \n",
      "Processing TCEA2 (chr20:+)\n",
      "LeafCutter junctions (43) All junctions (36) Start codons (2) Stop codons (2) \n",
      "Processing OPRL1 (chr20:+)\n",
      "LeafCutter junctions (8) All junctions (8) Start codons (1) Stop codons (2) \n",
      "Processing MYT1 (chr20:+)\n",
      "LeafCutter junctions (11) All junctions (34) Start codons (2) Stop codons (2) \n",
      "Processing PCMTD2 (chr20:+)\n",
      "LeafCutter junctions (25) All junctions (22) Start codons (1) Stop codons (2) \n"
     ]
    }
   ],
   "source": [
    "ClassifySpliceJunction('/project2/yangili1/qhauck/nmd_splicing_rules/add_on_script/chr20.gtf', '/project2/yangili1/qhauck/nmd_splicing_rules/add_on_script/juncs.perind.txt.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ClassifySpliceJunction(annot, countfile):\n",
    "    '''\n",
    "        - perind_file: str : path to counts file, e.g. leafcutter_perind.counts.gz\n",
    "        - gtf_annot: str : Annotation GTF file, for example gencode.v37.annotation.gtf.gz\n",
    "        - rundir: str : run directory, default is current directory\n",
    "    '''\n",
    "    rundir = '/project2/yangili1/qhauck/nmd_splicing_rules/add_on_script/'\n",
    "    gtf_annot = annot\n",
    "    \n",
    "    perind_file = countfile\n",
    "\n",
    "    # read leafcutter perind file and store junctions in dictionary: dic_junc\n",
    "    # key = (chrom,strand), value = list of junctions [(start,end)]\n",
    "    dic_junc = {}\n",
    "    sys.stdout.write(f\"Processing junction counts {perind_file}...\")\n",
    "    for ln in gzip.open(perind_file):\n",
    "        junc_info = ln.decode('ascii').split()[0] # first column\n",
    "        if junc_info == \"chrom\": continue # header\n",
    "        \n",
    "        chrom, start, end, clu_strand = junc_info.split(\":\")\n",
    "        strand = clu_strand.split(\"_\")[-1]\n",
    "        if (chrom,strand) not in dic_junc: \n",
    "            dic_junc[(chrom,strand)] = []\n",
    "        dic_junc[(chrom,strand)].append((int(start), int(end)))\n",
    "\n",
    "    sys.stdout.write(\"done!\\n\")\n",
    "    if verbose:\n",
    "        sys.stdout.write(\"Processed: \")\n",
    "        for chrstrand in dic_junc:\n",
    "            sys.stdout.write(f\"{len(dic_junc[chrstrand])} jxns on {chrstrand[0]} ({chrstrand[1]}).\")\n",
    "\n",
    "    \n",
    "    # load or parse gtf annotations\n",
    "    # g_coords: gene coordinates, grouped by chromosome and strand\n",
    "    # g_info: a dictionary with (transcript_name, gene_name) as keys, and intron info as values\n",
    "    try: \n",
    "        sys.stdout.write(\"Loading annotations...\\n\")\n",
    "        parsed_gtf = f\"{rundir}/{gtf_annot.split('/')[-1].split('.gtf')[0]}_SJC_annotations.pckle\"\n",
    "        with open(parsed_gtf, 'rb') as f:\n",
    "            g_coords, g_info = pickle.load(f)\n",
    "        sys.stdout.write(\"done!\\n\")\n",
    "    except:\n",
    "        sys.stdout.write(\"Parsing annotations for the first time...\\n\")\n",
    "        g_coords, g_info, ss2gene = parse_annotation(gtf_annot)\n",
    "        \n",
    "    \n",
    "        for chrom,strand in g_coords:\n",
    "            to_remove_gcoords = set()\n",
    "            to_remove_ginfo = set()\n",
    "            for gene in g_coords[(chrom,strand)]:\n",
    "                if gene[1] in g_info: # check if gene_name is in introns_info keys\n",
    "                    if len(g_info[gene[1]]['stop_codon']) == 0: # if there are no stop codons\n",
    "                        to_remove_gcoords.add(gene) # mark gene for remove\n",
    "                        to_remove_ginfo.add(gene[1]) # mark gene_name for removal\n",
    "\n",
    "            for g in to_remove_gcoords:\n",
    "                g_coords[(chrom,strand)].remove(g)\n",
    "            for g in to_remove_ginfo:\n",
    "                g_info.pop(g)\n",
    "        sys.stdout.write(\"Saving parsed annotations...\\n\")\n",
    "        with open(parsed_gtf, 'wb') as f:\n",
    "            pickle.dump((g_coords, g_info), f)\n",
    "\n",
    "    transcripts_by_gene = tx_by_gene(gtf_annot)\n",
    "\n",
    "    gene_juncs = {}\n",
    "    for chrom,strand in dic_junc:\n",
    "        if (chrom,strand) not in g_coords: \n",
    "            sys.stderr.write(f\"Could not find {chrom} ({strand}) in annotations...\\n\")\n",
    "            continue\n",
    "        juncs = [(x,x) for x in dic_junc[(chrom,strand)]]\n",
    "        juncs.sort()\n",
    "\n",
    "        coords = g_coords[(chrom,strand)]\n",
    "        coords.sort()\n",
    "        \n",
    "        # save junctions that overlapping a gene in gene_juncs dictionary: (gene_name, chrom, strand) : [junctions]\n",
    "        for junc, geneinfo in get_overlap_stream(juncs,coords): \n",
    "            info = (geneinfo[1], chrom,strand)\n",
    "            if info not in gene_juncs:\n",
    "                gene_juncs[info] = []\n",
    "            gene_juncs[info].append(junc[0])\n",
    "\n",
    "    #fout = open(f\"{rundir}/{outprefix}_junction_classifications.txt\",'w')\n",
    "    #fout.write(\"\\t\".join([\"Gene_name\",\"Intron_coord\",\"Annot\",\"Coding\", \"UTR\", \"Long_exon\"])+'\\n')\n",
    "    \n",
    "    for gene_name, chrom, strand in gene_juncs:\n",
    "        sys.stdout.write(f\"Processing {gene_name} ({chrom}:{strand})\\n\")\n",
    "        \n",
    "        query_juncs = gene_juncs[(gene_name,chrom,strand)] # from LeafCutter perind file\n",
    "        if gene_name not in g_info: continue\n",
    "        junctions = g_info[gene_name]['junctions'] # from annotation\n",
    "        \n",
    "        # classify all junctions in gene\n",
    "        junctions = list(junctions.union(query_juncs))\n",
    "\n",
    "        start_codons = g_info[gene_name]['start_codon'] \n",
    "        stop_codons = g_info[gene_name]['stop_codon']\n",
    "\n",
    "        if verbose:\n",
    "            sys.stdout.write(f\"LeafCutter junctions ({len(query_juncs)}) All junctions ({len(junctions)}) Start codons ({len(start_codons)}) Stop codons ({len(stop_codons)}) \\n\")\n",
    "\n",
    "        junc_pass, junc_fail, proteins = solve_NMD(chrom,strand,junctions, \n",
    "                                                   start_codons, stop_codons, \n",
    "                                                   gene_name)\n",
    "        \n",
    "\n",
    "        junc_fail = set(junc_fail.keys())\n",
    "        junc_pass = set(junc_pass.keys())\n",
    "        failing_juncs = junc_fail.difference(junc_pass)\n",
    "\n",
    "        old_junc_pass = junc_pass\n",
    "        junc_pass = {}\n",
    "        junc_pass['normal'] = old_junc_pass\n",
    "  \n",
    "        junc_pass['long_exon'] = long_exon_finder(failing_juncs, gene_name, transcripts_by_gene, strand, chrom)\n",
    "\n",
    "        for j in junctions:\n",
    "            bool_pass = j in junc_pass['normal'] or j in g_info[gene_name]['pcjunctions']\n",
    "            bool_fail = j in junc_fail or j in junc_pass['long_exon']\n",
    "            utr = False\n",
    "            long_exon = j in junc_pass['long_exon'] and not bool_pass\n",
    "            if not bool_pass:\n",
    "                # Check that it's not in UTR                \n",
    "                utr = check_utrs(j,g_info[gene_name]['utrs'])\n",
    "\n",
    "            if bool_fail or bool_pass:\n",
    "                tested = True\n",
    "            else:\n",
    "                tested = False\n",
    "            annotated = j in g_info[gene_name]['junctions']\n",
    "            #if not bool_pass and annotated:\n",
    "            #print(\"%s %s %s junction: %s tested: %s utr: %s coding: %s annotated: %s \"%(chrom, strand, gene_name, j, tested,utr, bool_pass, annotated))\n",
    "            \n",
    "            #fout.write('\\t'.join([gene_name, f'{chrom}:{j[0]}-{j[1]}',\n",
    "            #str(annotated), str(bool_pass), str(utr), str(long_exon)])+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chrom': 'chr1', 'source': 'HAVANA', 'type': 'gene', 'start': '11869', 'end': '14409', '.': '.', 'strand': '+', 'frame': '.', 'info': 'gene_id \"ENSG00000223972.5\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; level 2; hgnc_id \"HGNC:37102\"; havana_gene \"OTTHUMG00000000961.2\";', 'gene_name': 'DDX11L1', 'transcript_type': None, 'transcript_name': None, 'gene_type': 'transcribed_unprocessed_pseudogene'}\n",
      "{'chrom': 'chr1', 'source': 'HAVANA', 'type': 'transcript', 'start': '11869', 'end': '14409', '.': '.', 'strand': '+', 'frame': '.', 'info': 'gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000456328.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"processed_transcript\"; transcript_name \"DDX11L1-202\"; level 2; transcript_support_level \"1\"; hgnc_id \"HGNC:37102\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000362751.1\";', 'gene_name': 'DDX11L1', 'transcript_type': 'processed_transcript', 'transcript_name': 'DDX11L1-202', 'gene_type': 'transcribed_unprocessed_pseudogene'}\n",
      "{'chrom': 'chr1', 'source': 'HAVANA', 'type': 'exon', 'start': '11869', 'end': '12227', '.': '.', 'strand': '+', 'frame': '.', 'info': 'gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000456328.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"processed_transcript\"; transcript_name \"DDX11L1-202\"; exon_number 1; exon_id \"ENSE00002234944.1\"; level 2; transcript_support_level \"1\"; hgnc_id \"HGNC:37102\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000362751.1\";', 'gene_name': 'DDX11L1', 'transcript_type': 'processed_transcript', 'transcript_name': 'DDX11L1-202', 'gene_type': 'transcribed_unprocessed_pseudogene'}\n",
      "{'chrom': 'chr1', 'source': 'HAVANA', 'type': 'exon', 'start': '12613', 'end': '12721', '.': '.', 'strand': '+', 'frame': '.', 'info': 'gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000456328.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"processed_transcript\"; transcript_name \"DDX11L1-202\"; exon_number 2; exon_id \"ENSE00003582793.1\"; level 2; transcript_support_level \"1\"; hgnc_id \"HGNC:37102\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000362751.1\";', 'gene_name': 'DDX11L1', 'transcript_type': 'processed_transcript', 'transcript_name': 'DDX11L1-202', 'gene_type': 'transcribed_unprocessed_pseudogene'}\n",
      "{'chrom': 'chr1', 'source': 'HAVANA', 'type': 'exon', 'start': '13221', 'end': '14409', '.': '.', 'strand': '+', 'frame': '.', 'info': 'gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000456328.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"processed_transcript\"; transcript_name \"DDX11L1-202\"; exon_number 3; exon_id \"ENSE00002312635.1\"; level 2; transcript_support_level \"1\"; hgnc_id \"HGNC:37102\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000362751.1\";', 'gene_name': 'DDX11L1', 'transcript_type': 'processed_transcript', 'transcript_name': 'DDX11L1-202', 'gene_type': 'transcribed_unprocessed_pseudogene'}\n",
      "{'chrom': 'chr1', 'source': 'HAVANA', 'type': 'transcript', 'start': '12010', 'end': '13670', '.': '.', 'strand': '+', 'frame': '.', 'info': 'gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000450305.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"transcribed_unprocessed_pseudogene\"; transcript_name \"DDX11L1-201\"; level 2; transcript_support_level \"NA\"; hgnc_id \"HGNC:37102\"; ont \"PGO:0000005\"; ont \"PGO:0000019\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000002844.2\";', 'gene_name': 'DDX11L1', 'transcript_type': 'transcribed_unprocessed_pseudogene', 'transcript_name': 'DDX11L1-201', 'gene_type': 'transcribed_unprocessed_pseudogene'}\n",
      "{'chrom': 'chr1', 'source': 'HAVANA', 'type': 'exon', 'start': '12010', 'end': '12057', '.': '.', 'strand': '+', 'frame': '.', 'info': 'gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000450305.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"transcribed_unprocessed_pseudogene\"; transcript_name \"DDX11L1-201\"; exon_number 1; exon_id \"ENSE00001948541.1\"; level 2; transcript_support_level \"NA\"; hgnc_id \"HGNC:37102\"; ont \"PGO:0000005\"; ont \"PGO:0000019\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000002844.2\";', 'gene_name': 'DDX11L1', 'transcript_type': 'transcribed_unprocessed_pseudogene', 'transcript_name': 'DDX11L1-201', 'gene_type': 'transcribed_unprocessed_pseudogene'}\n",
      "{'chrom': 'chr1', 'source': 'HAVANA', 'type': 'exon', 'start': '12179', 'end': '12227', '.': '.', 'strand': '+', 'frame': '.', 'info': 'gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000450305.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"transcribed_unprocessed_pseudogene\"; transcript_name \"DDX11L1-201\"; exon_number 2; exon_id \"ENSE00001671638.2\"; level 2; transcript_support_level \"NA\"; hgnc_id \"HGNC:37102\"; ont \"PGO:0000005\"; ont \"PGO:0000019\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000002844.2\";', 'gene_name': 'DDX11L1', 'transcript_type': 'transcribed_unprocessed_pseudogene', 'transcript_name': 'DDX11L1-201', 'gene_type': 'transcribed_unprocessed_pseudogene'}\n",
      "{'chrom': 'chr1', 'source': 'HAVANA', 'type': 'exon', 'start': '12613', 'end': '12697', '.': '.', 'strand': '+', 'frame': '.', 'info': 'gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000450305.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"transcribed_unprocessed_pseudogene\"; transcript_name \"DDX11L1-201\"; exon_number 3; exon_id \"ENSE00001758273.2\"; level 2; transcript_support_level \"NA\"; hgnc_id \"HGNC:37102\"; ont \"PGO:0000005\"; ont \"PGO:0000019\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000002844.2\";', 'gene_name': 'DDX11L1', 'transcript_type': 'transcribed_unprocessed_pseudogene', 'transcript_name': 'DDX11L1-201', 'gene_type': 'transcribed_unprocessed_pseudogene'}\n",
      "{'chrom': 'chr1', 'source': 'HAVANA', 'type': 'exon', 'start': '12975', 'end': '13052', '.': '.', 'strand': '+', 'frame': '.', 'info': 'gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000450305.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"transcribed_unprocessed_pseudogene\"; transcript_name \"DDX11L1-201\"; exon_number 4; exon_id \"ENSE00001799933.2\"; level 2; transcript_support_level \"NA\"; hgnc_id \"HGNC:37102\"; ont \"PGO:0000005\"; ont \"PGO:0000019\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000002844.2\";', 'gene_name': 'DDX11L1', 'transcript_type': 'transcribed_unprocessed_pseudogene', 'transcript_name': 'DDX11L1-201', 'gene_type': 'transcribed_unprocessed_pseudogene'}\n",
      "{'chrom': 'chr1', 'source': 'HAVANA', 'type': 'exon', 'start': '13221', 'end': '13374', '.': '.', 'strand': '+', 'frame': '.', 'info': 'gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000450305.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"transcribed_unprocessed_pseudogene\"; transcript_name \"DDX11L1-201\"; exon_number 5; exon_id \"ENSE00001746346.2\"; level 2; transcript_support_level \"NA\"; hgnc_id \"HGNC:37102\"; ont \"PGO:0000005\"; ont \"PGO:0000019\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000002844.2\";', 'gene_name': 'DDX11L1', 'transcript_type': 'transcribed_unprocessed_pseudogene', 'transcript_name': 'DDX11L1-201', 'gene_type': 'transcribed_unprocessed_pseudogene'}\n",
      "{'chrom': 'chr1', 'source': 'HAVANA', 'type': 'exon', 'start': '13453', 'end': '13670', '.': '.', 'strand': '+', 'frame': '.', 'info': 'gene_id \"ENSG00000223972.5\"; transcript_id \"ENST00000450305.2\"; gene_type \"transcribed_unprocessed_pseudogene\"; gene_name \"DDX11L1\"; transcript_type \"transcribed_unprocessed_pseudogene\"; transcript_name \"DDX11L1-201\"; exon_number 6; exon_id \"ENSE00001863096.1\"; level 2; transcript_support_level \"NA\"; hgnc_id \"HGNC:37102\"; ont \"PGO:0000005\"; ont \"PGO:0000019\"; tag \"basic\"; havana_gene \"OTTHUMG00000000961.2\"; havana_transcript \"OTTHUMT00000002844.2\";', 'gene_name': 'DDX11L1', 'transcript_type': 'transcribed_unprocessed_pseudogene', 'transcript_name': 'DDX11L1-201', 'gene_type': 'transcribed_unprocessed_pseudogene'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gtf_annot = '/project2/yangili1/qhauck/nmd_splicing_rules/add_on_script/OR4F5.gtf'\n",
    "\n",
    "genes_info = {}\n",
    "introns_info = {}\n",
    "genes_coords = {}\n",
    "ss2gene = {}\n",
    "\n",
    "for dic in parse_gtf(gtf_annot):\n",
    "    print(dic)\n",
    "    chrom = dic['chrom']\n",
    "    gname = dic['gene_name']\n",
    "    tname = dic['transcript_name'], gname\n",
    "    anntype  = dic['type']\n",
    "    if dic['type'] == 'gene': \n",
    "        dic['transcript_type'] = \"gene\"\n",
    "    if dic['transcript_type'] == \"nonsense_mediated_decay\" and anntype == \"stop_codon\": \n",
    "        continue \n",
    "    if dic['transcript_type'] != \"protein_coding\" and anntype == \"UTR\": \n",
    "        continue\n",
    "    \"\"\"Quinn: CONVERT TO BED FORMAT IS ERROR\"\"\"\n",
    "    start, end = int(dic['start']), int(dic['end']) # convert to BED format\n",
    "    strand = dic['strand']\n",
    "\n",
    "    if (chrom, strand) not in genes_coords:\n",
    "        genes_coords[(chrom, strand)] = []\n",
    "\n",
    "    if tname not in genes_info: # tname is (transcript_name, gene_name)\n",
    "        genes_info[tname] = {'exons':[],\n",
    "                                'start_codon':set(), \n",
    "                                'stop_codon':set(), \n",
    "                                'utrs':set(),\n",
    "                                'type':dic['transcript_type']\n",
    "                                }\n",
    "    \n",
    "    if anntype in [\"start_codon\", \"stop_codon\"]:\n",
    "        genes_info[tname][anntype].add((start,end))\n",
    "    elif anntype in [\"gene\"]:\n",
    "        genes_coords[(chrom,strand)].append(((start,end), gname))\n",
    "    elif anntype in ['exon']:\n",
    "        genes_info[tname]['exons'].append((start,end))\n",
    "        # Store gene info for splice sites\n",
    "        ss2gene[(chrom, int(dic['start']))] = dic['gene_name'] # BED\n",
    "        ss2gene[(chrom, int(dic['end']))] = dic['gene_name'] # BED\n",
    "\n",
    "    elif anntype in ['UTR']:\n",
    "        genes_info[tname]['utrs'].add((start,end))\n",
    "\n",
    "for gene in genes_info: # this is actually transcript level!!! (transcript_name, gene_name)\n",
    "    gene_name = gene[1]\n",
    "    exons = genes_info[gene]['exons']\n",
    "    exons.sort()\n",
    "\n",
    "    pc = False # Basically use transcript_type == protein_coding to set flag\n",
    "    if genes_info[gene]['type'] == \"protein_coding\": # AGAIN here gene = (transcript_name, gene_name)\n",
    "        pc = True\n",
    "\n",
    "    junctions = set() # all junctions/introns\n",
    "    pcjunctions = set() # only protein coding junctions/introns\n",
    "\n",
    "    for i in range(len(exons)-1):\n",
    "        intron = (exons[i][1], exons[i+1][0])\n",
    "        junctions.add(intron)\n",
    "        if pc:\n",
    "            pcjunctions.add(intron)\n",
    "\n",
    "    if gene_name not in introns_info: # here only gene_name, does not incl. transcript_name\n",
    "        introns_info[gene_name] = {'junctions':set(),\n",
    "                                    'start_codon':set(),\n",
    "                                    'stop_codon':set(),\n",
    "                                    'utrs':set(),\n",
    "                                    'pcjunctions':set(),\n",
    "                                }\n",
    "\n",
    "    introns_info[gene_name]['start_codon'] = introns_info[gene_name]['start_codon'].union(genes_info[gene]['start_codon'])\n",
    "    introns_info[gene_name]['stop_codon'] = introns_info[gene_name]['stop_codon'].union(genes_info[gene]['stop_codon'])\n",
    "    introns_info[gene_name]['junctions'] = introns_info[gene_name]['junctions'].union(junctions)\n",
    "    introns_info[gene_name]['utrs'] = introns_info[gene_name]['utrs'].union(genes_info[gene]['utrs'])\n",
    "    introns_info[gene_name]['pcjunctions'] = introns_info[gene_name]['pcjunctions'].union(pcjunctions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(None, 'DDX11L1'): {'exons': [],\n",
       "  'start_codon': set(),\n",
       "  'stop_codon': set(),\n",
       "  'utrs': set(),\n",
       "  'type': 'gene'},\n",
       " ('DDX11L1-202',\n",
       "  'DDX11L1'): {'exons': [(11869, 12227),\n",
       "   (12613, 12721),\n",
       "   (13221,\n",
       "    14409)], 'start_codon': set(), 'stop_codon': set(), 'utrs': set(), 'type': 'processed_transcript'},\n",
       " ('DDX11L1-201',\n",
       "  'DDX11L1'): {'exons': [(12010, 12057),\n",
       "   (12179, 12227),\n",
       "   (12613, 12697),\n",
       "   (12975, 13052),\n",
       "   (13221, 13374),\n",
       "   (13453,\n",
       "    13670)], 'start_codon': set(), 'stop_codon': set(), 'utrs': set(), 'type': 'transcribed_unprocessed_pseudogene'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpliceJunctionClassified V0.1 (Updated Jan 2024)\n",
    "# Written by Yang Li Nov-2023\n",
    "\n",
    "\n",
    "\n",
    "def check_utrs(junc,utrs):\n",
    "    '''\n",
    "    checks if junction is close or within 100bp of UTRs\n",
    "    '''\n",
    "    for s1,s2 in list(utrs):\n",
    "        if abs(junc[0]-s1) < 100 or abs(junc[1]-s2) < 100:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def solve_NMD(chrom, strand, junc, start_codons, stop_codons,gene_name, \n",
    "              verbose = False, exonLcutoff = 1000):\n",
    "    '''\n",
    "    Compute whether there is a possible combination that uses the junction without\n",
    "    inducing a PTC. We start with all annotated stop codon and go backwards.\n",
    "    '''\n",
    "\n",
    "    global fa\n",
    "    \n",
    "    seed = []\n",
    "\n",
    "    junc.sort()\n",
    "    if strand == \"+\":\n",
    "        junc.reverse()\n",
    "        \n",
    "    \"\"\"Quinn Comment: Adds all 'stop codons' to a nested list called seed\"\"\" \n",
    "    ##in an individual transcript    \n",
    "    for c in stop_codons:\n",
    "        if strand == \"+\":\n",
    "            seed.append([c[1]])\n",
    "        else:\n",
    "            seed.append([c[0]])\n",
    "\n",
    "    # seed starts with just stop codon and then a possible 3'ss-5'ss junction\n",
    "    # without introducing a PTC [stop_codon,3'ss, 5'ss, 3'ss, ..., start_codon]\n",
    "    \n",
    "    seq_db = {}\n",
    "    junc_pass = {}\n",
    "    junc_fail = {}\n",
    "    path_pass = []\n",
    "    proteins = []\n",
    "    \n",
    "    dic_terminus = {}\n",
    "    dic_paths = {}\n",
    "\n",
    "    depth = 0\n",
    "\n",
    "    \"\"\"Quinn Comment: while our seed length is greater than 0 - which means we have charted all possible paths through \n",
    "    all junctions ending in a stop codon (or there is an exon longer than 1000 bp and we have no complete paths)\"\"\"\n",
    "    while len(seed) > 0:\n",
    "        new_seed = []\n",
    "        final_check = []\n",
    "        depth += 1\n",
    "        if verbose:\n",
    "            sys.stdout.write(\"Depth %s, Seed L = %s\\n\"%(depth, len(seed)))\n",
    "        #print(start_codons, [s[-1] for s in seed][-10:], len(junc))\n",
    "        framepos = {}\n",
    "                    \n",
    "        for s in seed:\n",
    "            # first check that the seed paths are good        \n",
    "            bool_ptc = False\n",
    "            leftover = ''\n",
    "            if len(s) > 0:                \n",
    "                leftover = Seq(\"\")\n",
    "                allprot = Seq(\"\")\n",
    "\n",
    "                \"\"\"Quinn Comment: loop through the exons, calculating lengths\"\"\"\n",
    "                for i in range(0, len(s)-1, 2):\n",
    "                    exon_coord = s[i:i+2]\n",
    "                    exon_coord.sort()\n",
    "                    exon_coord = tuple(exon_coord)\n",
    "                    exlen = exon_coord[1]-exon_coord[0]\n",
    "\n",
    "\n",
    "                    \"\"\"Quinn Comment: find start position relative to named start of this exon and translate to protein\"\"\"\n",
    "                    \"\"\"Quinn Comment: Coordinates from PERIND file and GTF file are exon start and end coordinates, so \n",
    "                    we must add 1 to length\"\"\"\n",
    "                    startpos = (len(leftover)+exlen+1)%3\n",
    "                    if strand == '+':\n",
    "                        seq = Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))+leftover \n",
    "                        prot = seq[startpos:].translate()\n",
    "                        leftover = seq[:startpos]                                                                                                               \n",
    "                        allprot = prot+allprot  \n",
    "                    else:\n",
    "                        seq = leftover+Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))\n",
    "                        aseq = seq\n",
    "                        if startpos > 0:\n",
    "                            leftover = seq[-startpos:]\n",
    "                        else:\n",
    "                            leftover = Seq(\"\")\n",
    "                        seq = seq.reverse_complement()\n",
    "                        prot = seq[startpos:].translate()\n",
    "                        allprot = prot+allprot\n",
    "\n",
    "                    #found a PTC in this transcript if any element but the last is a stop codon    \n",
    "                    bool_ptc = \"*\" in allprot[:-1]\n",
    "\n",
    "            \"\"\"Quinn Comment: if we found a PTC, add all intron coordinate pairs involved in the transcript to junc_fail\"\"\"        \n",
    "            if bool_ptc:\n",
    "                #This transcript failed\n",
    "                for i in range(1, len(s)-1, 2):                                                                                                                  \n",
    "                    j_coord = s[i:i+2]                                                                                                                           \n",
    "                    j_coord.sort()                                                                                                                             \n",
    "                    j_coord = tuple(j_coord)                                                                                                                     \n",
    "                    if j_coord not in junc_fail:                                                                                                                 \n",
    "                        junc_fail[j_coord] = 0                                                                                                                   \n",
    "                    junc_fail[j_coord] += 1  \n",
    "\n",
    "                continue\n",
    "        \n",
    "            # passed\n",
    "            \"\"\"Quinn Comment: if we don't just have a stop codon, create a terminus for this \n",
    "            seed at the last 3' splice site or start codon; terminus is last two coordinates and the reading frame, \n",
    "            used for dynamic programming later\"\"\"\n",
    "            if len(s) > 2:\n",
    "                terminus = (s[-2],s[-1],leftover)\n",
    "                \n",
    "                if terminus in dic_terminus:\n",
    "                    dic_terminus[terminus].append(tuple(s))\n",
    "                    continue\n",
    "                else:\n",
    "                    dic_terminus[terminus] = [tuple(s)]\n",
    "            \n",
    "            last_pos = s[-1]\n",
    "            \n",
    "            \"\"\"Quinn Comment: check the last position of our seed to see if it is close to a start codon, within a potential exon's length,\n",
    "             and add your seed plus this start codon to final_check \"\"\"\n",
    "            for start in start_codons:                \n",
    "                #print(\"start\", start, abs(last_pos-start[0]))\n",
    "                if strand == \"+\" and last_pos > start[0] and abs(last_pos-start[0]) < exonLcutoff:\n",
    "                    final_check.append(s+[start[0]])\n",
    "                elif strand == \"-\" and last_pos < start[1] and abs(last_pos-start[1]) < exonLcutoff:\n",
    "                    final_check.append(s+[start[1]]) \n",
    "\n",
    "            \"\"\"Quinn Comment: add all possible places to go from our last_pos to the seed (nested list)\"\"\"\n",
    "            for j0,j1 in junc:                \n",
    "                if strand == \"+\" and last_pos > j1 and abs(last_pos-j1) < exonLcutoff:\n",
    "                    new_seed.append(s+[j1,j0])\n",
    "                #print(\"junction\", (j0,j1), abs(last_pos-j0))\n",
    "                if strand == \"-\" and last_pos < j0 and abs(last_pos-j0) < exonLcutoff: \n",
    "                    new_seed.append(s+[j0,j1])\n",
    "                    \n",
    "        \"\"\"Quinn Comment: Exited from s in seed loop, now we check our final_checks of the full paths, we do not\n",
    "        eliminate paths based on presence of a PTC, rather we classify full complete paths without PTCs if they exist\"\"\"\n",
    "        # check that the possible final paths are good\n",
    "        for s in final_check:\n",
    "            leftover = Seq(\"\")\n",
    "            allprot = Seq(\"\")\n",
    "            for i in range(0, len(s)-1, 2):\n",
    "                exon_coord = s[i:i+2]\n",
    "                exon_coord.sort()\n",
    "                exon_coord = tuple(exon_coord)\n",
    "                exlen = exon_coord[1]-exon_coord[0]\n",
    "                startpos = (len(leftover)+exlen+1)%3\n",
    "                if strand == \"+\":\n",
    "                    seq = Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))+leftover\n",
    "                    leftover = seq[:startpos]  \n",
    "                    prot = seq[startpos:].translate()\n",
    "                    allprot = prot+allprot\n",
    "                else:\n",
    "                    seq = leftover+Seq(fa.fetch(chrom, (exon_coord[0],exon_coord[1])))\n",
    "                    if startpos > 0:                                                                                                    \n",
    "                        leftover = seq[-startpos:]                                    \n",
    "                    else:\n",
    "                        leftover = Seq(\"\")\n",
    "                    seq = seq.reverse_complement()                                                                                                           \n",
    "                    prot = seq[startpos:].translate()                                                                                                        \n",
    "                    allprot = prot+allprot                    \n",
    "            bool_ptc = \"*\" in allprot[:-1]\n",
    "        \n",
    "            \"\"\"Quinn Comment: Classify seed + start codon as a passing path if no PTCs found in previous block of code\"\"\"\n",
    "            if not bool_ptc:\n",
    "                # all pass\n",
    "                proteins.append(\"\\t\".join([gene_name,chrom,strand, \"-\".join([str(x) for x in s]), str(allprot)])+'\\n')\n",
    "                #print(\"ALL PASS %s\"%(s))\n",
    "                path_pass.append(tuple(s))\n",
    "                for i in range(1, len(s), 2):\n",
    "                    j_coord = s[i:i+2]\n",
    "                    j_coord.sort()\n",
    "                    j_coord = tuple(j_coord)\n",
    "                    if j_coord not in junc_pass:\n",
    "                        junc_pass[j_coord] = 0\n",
    "                    junc_pass[j_coord] += 1\n",
    "\n",
    "        seed = new_seed\n",
    "    \n",
    "    \n",
    "    \"\"\"Quinn Comment: OUT OF WHILE LOOP through all possible paths/seeds; \n",
    "    check all terminus' to see if they are part of a full path that has been classified as passing\"\"\"\n",
    "    while True:\n",
    "        new_paths = []\n",
    "        for terminus in dic_terminus:\n",
    "            terminus_pass = False\n",
    "            for path_subset in dic_terminus[terminus]:\n",
    "                for path in path_pass:\n",
    "                    if path[:len(path_subset)] == path_subset:\n",
    "                        terminus_pass = True\n",
    "                        break\n",
    "            #print(terminus, terminus_pass)\n",
    "\n",
    "            \"\"\"Quinn Comment: if our terminus is part of a passing path, we want to make sure if is reflected in passing paths and\n",
    "            add the associate junctions to junc_pass, only if they are not present\"\"\"\n",
    "            if terminus_pass:\n",
    "                for path_subset in dic_terminus[terminus]:\n",
    "                    if path_subset in path_pass: continue\n",
    "                    new_paths.append(path_subset)\n",
    "                    path_pass.append(path_subset)\n",
    "                    for i in range(1, len(path_subset), 2):\n",
    "                        j_coord = list(path_subset[i:i+2])\n",
    "                        j_coord.sort()\n",
    "                        j_coord = tuple(j_coord)\n",
    "                        if j_coord not in junc_pass:\n",
    "                            junc_pass[j_coord] = 0\n",
    "                            if verbose:\n",
    "                                sys.stdout.write(\"junction %s pass\\n\"%j_coord)\n",
    "        \"\"\"Quinn Comment: we could have a new path_pass added, so our while loop checks again to see if there are any new paths \n",
    "        that are now going to be passing considering our additions\"\"\"\n",
    "        if len(new_paths) == 0:\n",
    "            break\n",
    "            \n",
    "    return junc_pass,junc_fail,proteins\n",
    "\n",
    "def parse_gtf(gtf: str):\n",
    "    '''Lower level function to parse GTF file\n",
    "    - gtf: str : path to GTF annotation file\n",
    "    - returns: dictionary with keys: \n",
    "        chrom, source, type, start, end, strand, frame, info, gene_name, transcript_type, transcript_name, gene_type\n",
    "    '''\n",
    "    fields = [\"chrom\", \"source\", \"type\", \"start\", \"end\", \".\",\"strand\",\"frame\", \"info\"]\n",
    "    open_gtf = lambda x: gzip.open(x) if \".gz\" in x else open(x)\n",
    "    for ln in open_gtf(gtf):\n",
    "        ln = ln.decode('ascii') if \".gz\" in gtf else ln\n",
    "        dic = {}\n",
    "        if ln[0] == \"#\": continue\n",
    "        ln = ln.strip().split('\\t')\n",
    "        for i in range(len(fields)):\n",
    "            dic[fields[i]] = ln[i]\n",
    "\n",
    "        # add 4 additional fields, parsed from info field\n",
    "        for ks in ['gene_name', \"transcript_type\",\"transcript_name\", \"gene_type\"]:\n",
    "            info_fields = [{x.split()[0]: x.split()[1].replace('\"', '')} \n",
    "                          for x in dic['info'].split(';') if len(x.split()) > 1]\n",
    "            info_fields = {k: v for d in info_fields for k, v in d.items()}\n",
    "            try: \n",
    "                dic[ks] = info_fields[ks]\n",
    "            except:\n",
    "                dic[ks] = None # if line is a gene, then wont have transcript info\n",
    "        yield dic\n",
    "         \n",
    "\n",
    "def parse_annotation(gtf_annot: str):\n",
    "    '''\n",
    "    Used `parse_gtf` to first parse a gtf file, then extract and return further\n",
    "    information, including gene coordinates, intron info, and splice site to \n",
    "    gene-name dictionary.\n",
    "    \n",
    "    - gtf_anno: str : path to GTF annotation file\n",
    "    - returns: \n",
    "        - genes_coords: gene coordinates, grouped by chromosome and strand \n",
    "        - introns_info: a dictionary with these keys: junctions (ie all introns),\n",
    "                        start_codon, stop_codon, utrs, pcjunctions (ie only protein coding introns) \n",
    "        - ss2gene: a dictionary with splice site as keys, and gene name as values, eg. ('chr1', 11869): 'DDX11L1'\n",
    "    '''\n",
    "    genes_info = {}\n",
    "    introns_info = {}\n",
    "    genes_coords = {}\n",
    "    ss2gene = {}\n",
    "\n",
    "    for dic in parse_gtf(gtf_annot):\n",
    "        chrom = dic['chrom']\n",
    "        gname = dic['gene_name']\n",
    "        tname = dic['transcript_name'], gname\n",
    "        anntype  = dic['type']\n",
    "        if dic['type'] == 'gene': \n",
    "            dic['transcript_type'] = \"gene\"\n",
    "        if dic['transcript_type'] == \"nonsense_mediated_decay\" and anntype == \"stop_codon\": \n",
    "            continue \n",
    "        if dic['transcript_type'] != \"protein_coding\" and anntype == \"UTR\": \n",
    "            continue\n",
    "        \"\"\"Quinn: CONVERT TO BED FORMAT IS ERROR\"\"\"\n",
    "        start, end = int(dic['start']), int(dic['end']) # convert to BED format\n",
    "        strand = dic['strand']\n",
    "    \n",
    "        if (chrom, strand) not in genes_coords:\n",
    "            genes_coords[(chrom, strand)] = []\n",
    "\n",
    "        if tname not in genes_info: # tname is (transcript_name, gene_name)\n",
    "            genes_info[tname] = {'exons':[],\n",
    "                                 'start_codon':set(), \n",
    "                                 'stop_codon':set(), \n",
    "                                 'utrs':set(),\n",
    "                                 'type':dic['transcript_type']\n",
    "                                 }\n",
    "        \n",
    "        if anntype in [\"start_codon\", \"stop_codon\"]:\n",
    "            genes_info[tname][anntype].add((start,end))\n",
    "        elif anntype in [\"gene\"]:\n",
    "            genes_coords[(chrom,strand)].append(((start,end), gname))\n",
    "        elif anntype in ['exon']:\n",
    "            genes_info[tname]['exons'].append((start,end))\n",
    "            # Store gene info for splice sites\n",
    "            ss2gene[(chrom, int(dic['start']))] = dic['gene_name'] # BED\n",
    "            ss2gene[(chrom, int(dic['end']))] = dic['gene_name'] # BED\n",
    "\n",
    "        elif anntype in ['UTR']:\n",
    "            genes_info[tname]['utrs'].add((start,end))\n",
    "\n",
    "    for gene in genes_info: # this is actually transcript level!!! (transcript_name, gene_name)\n",
    "        gene_name = gene[1]\n",
    "        exons = genes_info[gene]['exons']\n",
    "        exons.sort()\n",
    "\n",
    "        pc = False # Basically use transcript_type == protein_coding to set flag\n",
    "        if genes_info[gene]['type'] == \"protein_coding\": # AGAIN here gene = (transcript_name, gene_name)\n",
    "            pc = True\n",
    "\n",
    "        junctions = set() # all junctions/introns\n",
    "        pcjunctions = set() # only protein coding junctions/introns\n",
    "\n",
    "        for i in range(len(exons)-1):\n",
    "            intron = (exons[i][1], exons[i+1][0])\n",
    "            junctions.add(intron)\n",
    "            if pc:\n",
    "                pcjunctions.add(intron)\n",
    "\n",
    "        if gene_name not in introns_info: # here only gene_name, does not incl. transcript_name\n",
    "            introns_info[gene_name] = {'junctions':set(),\n",
    "                                       'start_codon':set(),\n",
    "                                       'stop_codon':set(),\n",
    "                                       'utrs':set(),\n",
    "                                       'pcjunctions':set(),\n",
    "                                 }\n",
    "\n",
    "        introns_info[gene_name]['start_codon'] = introns_info[gene_name]['start_codon'].union(genes_info[gene]['start_codon'])\n",
    "        introns_info[gene_name]['stop_codon'] = introns_info[gene_name]['stop_codon'].union(genes_info[gene]['stop_codon'])\n",
    "        introns_info[gene_name]['junctions'] = introns_info[gene_name]['junctions'].union(junctions)\n",
    "        introns_info[gene_name]['utrs'] = introns_info[gene_name]['utrs'].union(genes_info[gene]['utrs'])\n",
    "        introns_info[gene_name]['pcjunctions'] = introns_info[gene_name]['pcjunctions'].union(pcjunctions)\n",
    "\n",
    "    return genes_coords, introns_info, ss2gene\n",
    "\n",
    "\n",
    "\n",
    "# def getmean(lst):\n",
    "#     return sum(lst)/float(len(lst))\n",
    "\n",
    "# def getmedian(lst):\n",
    "#     lst.sort()\n",
    "#     n = len(lst)\n",
    "#     if n < 1:\n",
    "#         return None\n",
    "#     if n % 2 == 1:\n",
    "#         return lst[n//2]\n",
    "#     else:\n",
    "#         return sum(lst[n//2-1:n//2+1])/2.0\n",
    "\n",
    "def get_feature(fname, feature = \"exon\"):\n",
    "    ss2gene = {}\n",
    "    if \".gz\" in fname:\n",
    "        F = gzip.open(fname)\n",
    "    else:\n",
    "        F = open(fname)\n",
    "    for ln in F:\n",
    "        if ln[0] == \"#\": continue\n",
    "        ln = ln.split('\\t')\n",
    "        gID = ln[-1].split('gene_name \"')[1].split('\"')[0]\n",
    "\n",
    "        if ln[2] != feature:\n",
    "            continue\n",
    "        ss2gene[(ln[0], int(ln[3]))] = gID\n",
    "        ss2gene[(ln[0], int(ln[4]))] = gID\n",
    "    return ss2gene\n",
    "\n",
    "\n",
    "def get_overlap_stream(L1, L2, relax = 0):\n",
    "    '''                                                                                                                                                                \n",
    "    L1 and L2 are sorted lists of tuples with key, values                                                                                                              \n",
    "    '''\n",
    "    i, j = 0, 0\n",
    "    while i < len(L1) and j < len(L2):\n",
    "        if L1[i][0][1] < L2[j][0][0]:\n",
    "            i += 1\n",
    "            continue\n",
    "        elif L2[j][0][1] < L1[i][0][0]:\n",
    "            j += 1\n",
    "            continue\n",
    "        else:\n",
    "            k = 0\n",
    "            # hits overlapping, check all L2 that may overlap with intron                                                                                              \n",
    "            while L2[j+k][0][0] <= L1[i][0][1]:\n",
    "                if overlaps(L1[i][0], L2[j+k][0]):\n",
    "                    yield L1[i], L2[j+k]\n",
    "                k += 1\n",
    "                if j+k == len(L2): break\n",
    "            i += 1\n",
    "\n",
    "def overlaps(A: tuple, B: tuple):\n",
    "    '''                                                                                                                                                                \n",
    "    Checks if A and B overlaps                                                                                                                                         \n",
    "    A: tuple : (start, end)\n",
    "    B: tuple : (start, end)\n",
    "    '''\n",
    "    if A[1] < B[0] or B[1] < A[0]:\n",
    "        return False\n",
    "    else: return True\n",
    "\n",
    "\n",
    "def ClassifySpliceJunction(options):\n",
    "    '''\n",
    "        - perind_file: str : path to counts file, e.g. leafcutter_perind.counts.gz\n",
    "        - gtf_annot: str : Annotation GTF file, for example gencode.v37.annotation.gtf.gz\n",
    "        - rundir: str : run directory, default is current directory\n",
    "    '''\n",
    "\n",
    "    gtf_annot, rundir, outprefix = options.annot, options.rundir, options.outprefix\n",
    "    verbose = False or options.verbose\n",
    "    if options.countfile is None:\n",
    "        perind_file = f\"{rundir}/{outprefix}_perind.counts.gz\"\n",
    "    else:\n",
    "        perind_file = options.countfile\n",
    "\n",
    "    # read leafcutter perind file and store junctions in dictionary: dic_junc\n",
    "    # key = (chrom,strand), value = list of junctions [(start,end)]\n",
    "    dic_junc = {}\n",
    "    sys.stdout.write(f\"Processing junction counts {perind_file}...\")\n",
    "    for ln in gzip.open(perind_file):\n",
    "        junc_info = ln.decode('ascii').split()[0] # first column\n",
    "        if junc_info == \"chrom\": continue # header\n",
    "        \n",
    "        chrom, start, end, clu_strand = junc_info.split(\":\")\n",
    "        strand = clu_strand.split(\"_\")[-1]\n",
    "        if (chrom,strand) not in dic_junc: \n",
    "            dic_junc[(chrom,strand)] = []\n",
    "        dic_junc[(chrom,strand)].append((int(start), int(end)))\n",
    "\n",
    "    sys.stdout.write(\"done!\\n\")\n",
    "    if verbose:\n",
    "        sys.stdout.write(\"Processed: \")\n",
    "        for chrstrand in dic_junc:\n",
    "            sys.stdout.write(f\"{len(dic_junc[chrstrand])} jxns on {chrstrand[0]} ({chrstrand[1]}).\")\n",
    "\n",
    "    \n",
    "    # load or parse gtf annotations\n",
    "    # g_coords: gene coordinates, grouped by chromosome and strand\n",
    "    # g_info: a dictionary with (transcript_name, gene_name) as keys, and intron info as values\n",
    "    try: \n",
    "        sys.stdout.write(\"Loading annotations...\\n\")\n",
    "        parsed_gtf = f\"{rundir}/{gtf_annot.split('/')[-1].split('.gtf')[0]}_SJC_annotations.pckle\"\n",
    "        with open(parsed_gtf, 'rb') as f:\n",
    "            g_coords, g_info = pickle.load(f)\n",
    "        sys.stdout.write(\"done!\\n\")\n",
    "    except:\n",
    "        sys.stdout.write(\"Parsing annotations for the first time...\\n\")\n",
    "        g_coords, g_info, ss2gene = parse_annotation(gtf_annot)\n",
    "        \n",
    "        for chrom,strand in g_coords:\n",
    "            to_remove_gcoords = set()\n",
    "            to_remove_ginfo = set()\n",
    "            for gene in g_coords[(chrom,strand)]:\n",
    "                if gene[1] in g_info: # check if gene_name is in introns_info keys\n",
    "                    if len(g_info[gene[1]]['stop_codon']) == 0: # if there are no stop codons\n",
    "                        to_remove_gcoords.add(gene) # mark gene for remove\n",
    "                        to_remove_ginfo.add(gene[1]) # mark gene_name for removal\n",
    "\n",
    "            for g in to_remove_gcoords:\n",
    "                g_coords[(chrom,strand)].remove(g)\n",
    "            for g in to_remove_ginfo:\n",
    "                g_info.pop(g)\n",
    "        sys.stdout.write(\"Saving parsed annotations...\\n\")\n",
    "        with open(parsed_gtf, 'wb') as f:\n",
    "            pickle.dump((g_coords, g_info), f)\n",
    "\n",
    "    gene_juncs = {}\n",
    "    for chrom,strand in dic_junc:\n",
    "        if (chrom,strand) not in g_coords: \n",
    "            sys.stderr.write(f\"Could not find {chrom} ({strand}) in annotations...\\n\")\n",
    "            continue\n",
    "        juncs = [(x,x) for x in dic_junc[(chrom,strand)]]\n",
    "        juncs.sort()\n",
    "\n",
    "        coords = g_coords[(chrom,strand)]\n",
    "        coords.sort()\n",
    "        \n",
    "        # save junctions that overlapping a gene in gene_juncs dictionary: (gene_name, chrom, strand) : [junctions]\n",
    "        for junc, geneinfo in get_overlap_stream(juncs,coords): \n",
    "            info = (geneinfo[1], chrom,strand)\n",
    "            if info not in gene_juncs:\n",
    "                gene_juncs[info] = []\n",
    "            gene_juncs[info].append(junc[0])\n",
    "\n",
    "    fout = open(f\"{rundir}/{outprefix}_junction_classifications.txt\",'w')\n",
    "    fout.write(\"\\t\".join([\"Gene_name\",\"Intron_coord\",\"Annot\",\"Coding\", \"UTR\"])+'\\n')\n",
    "    \n",
    "    for gene_name, chrom, strand in gene_juncs:\n",
    "        sys.stdout.write(f\"Processing {gene_name} ({chrom}:{strand})\\n\")\n",
    "        \n",
    "        query_juncs = gene_juncs[(gene_name,chrom,strand)] # from LeafCutter perind file\n",
    "        if gene_name not in g_info: continue\n",
    "        junctions = g_info[gene_name]['junctions'] # from annotation\n",
    "        \n",
    "        # classify all junctions in gene\n",
    "        junctions = list(junctions.union(query_juncs))\n",
    "\n",
    "        start_codons = g_info[gene_name]['start_codon'] \n",
    "        stop_codons = g_info[gene_name]['stop_codon']\n",
    "\n",
    "        if verbose:\n",
    "            sys.stdout.write(f\"LeafCutter junctions ({len(query_juncs)}) All junctions ({len(junctions)}) Start codons ({len(start_codons)}) Stop codons ({len(stop_codons)}) \\n\")\n",
    "\n",
    "        junc_pass, junc_fail, proteins = solve_NMD(chrom,strand,junctions, \n",
    "                                                   start_codons, stop_codons, \n",
    "                                                   gene_name)\n",
    "        \n",
    "        for j in junctions:\n",
    "            bool_pass = j in junc_pass or j in g_info[gene_name]['pcjunctions']\n",
    "            bool_fail = j in junc_fail\n",
    "            utr = False\n",
    "            if not bool_pass:\n",
    "                # Check that it's not in UTR                \n",
    "                utr = check_utrs(j,g_info[gene_name]['utrs'])\n",
    "\n",
    "            if bool_fail or bool_pass:\n",
    "                tested = True\n",
    "            else:\n",
    "                tested = False\n",
    "            annotated = j in g_info[gene_name]['junctions']\n",
    "            #if not bool_pass and annotated:\n",
    "            #print(\"%s %s %s junction: %s tested: %s utr: %s coding: %s annotated: %s \"%(chrom, strand, gene_name, j, tested,utr, bool_pass, annotated))\n",
    "            \n",
    "            fout.write('\\t'.join([gene_name, f'{chrom}:{j[0]}-{j[1]}',\n",
    "                                  str(annotated), str(bool_pass), str(utr)])+'\\n')\n",
    "        \n",
    "\n",
    "def boolean_to_bit(bool_vec):\n",
    "    # Convert boolean vector to string of \"1\"s and \"0\"s\n",
    "    bin_str = ''.join(['1' if b else '0' for b in bool_vec])\n",
    "    \n",
    "    # Convert this binary string into an integer\n",
    "    # bit_num = int(bin_str, 2)\n",
    "    \n",
    "    return bin_str\n",
    "            \n",
    "def merge_discordant_logics(sjc_file: str):\n",
    "    '''some junctions have multiple classifications. Use conservative approach\n",
    "    to merge them.\n",
    "    '''\n",
    "    sjc = pd.read_csv(sjc_file, sep = \"\\t\")\n",
    "\n",
    "    classifier = {\n",
    "        # each bit represents [ is annotated, is coding, is UTR ]\n",
    "        '000': 'UP', # UnProductive,\n",
    "        '001': 'NE', # NEither, not productive, but not considered unprod. due to close to UTR\n",
    "        '010': 'PR', # PRoductive\n",
    "        '100': 'UP', # UnProductive\n",
    "        '101': 'PR', # PRoductive\n",
    "        '110': 'PR' # PRoductive\n",
    "        }\n",
    "    \n",
    "    # group dt\n",
    "    sjc = sjc.groupby('Intron_coord').agg('max').reset_index()\n",
    "    # convert Annotation, Coding, UTR status to binary strings then to SJ categories\n",
    "    sjc['SJClass'] = sjc.apply(lambda x: boolean_to_bit(x[2:5]), axis=1).map(classifier)\n",
    "    \n",
    "    # convert df to dict\n",
    "    sjc = sjc.set_index('Intron_coord').to_dict(orient='index')\n",
    "    sjc = {tuple([k.split(':')[0]]) + tuple(k.split(':')[1].split('-')): v for k, v in sjc.items()}\n",
    "    sjc = {(k[0], int(k[1]), int(k[2])): v for k, v in sjc.items()}\n",
    "\n",
    "\n",
    "    return sjc\n",
    "    # sjc is a dcitionary with:\n",
    "    # - keys: intron coordinates, e.g. ('chr1', 1000, 2000)\n",
    "    # - values: a dictionary e.g. {'Gene_name': 'DNMBP', 'Annot': False, 'Coding': False, 'UTR': False, 'SJClass': 'UP'})\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
